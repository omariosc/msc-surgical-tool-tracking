{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10\n",
    "import supervision as sv\n",
    "\n",
    "model = YOLOv10(\"weights/yolov10l.pt\")\n",
    "\n",
    "# model.track(\"data/6DOF/Dataset.mp4\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Paths to your folders\n",
    "# dataset_path = \"/Volumes/Exodus/Data/ART-Net/\"\n",
    "\n",
    "# train_positive_images_path = os.path.join(dataset_path, \"Train/Train_Positive\")\n",
    "# train_negative_images_path = os.path.join(dataset_path, \"Train/Train_Negative\")\n",
    "# train_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_Tool_Mask\")\n",
    "# train_labels_path = os.path.join(dataset_path, \"labels/train\")\n",
    "\n",
    "# test_positive_images_path = os.path.join(dataset_path, \"Test/Test_Positive\")\n",
    "# test_negative_images_path = os.path.join(dataset_path, \"Test/Test_Negative\")\n",
    "# test_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_Tool_Mask\")\n",
    "# test_labels_path = os.path.join(dataset_path, \"labels/val\")\n",
    "\n",
    "# os.makedirs(train_labels_path, exist_ok=True)\n",
    "# os.makedirs(test_labels_path, exist_ok=True)\n",
    "\n",
    "# # Function to create YOLO annotations from masks\n",
    "# def create_annotations(images_path, masks_path, labels_path, n = None):\n",
    "#     if n is not None:\n",
    "#         image_files = sorted([f for f in os.listdir(images_path) if f.endswith(\".png\") and not f.startswith(\"._\")])[:n]\n",
    "#     else:\n",
    "#         image_files = sorted([f for f in os.listdir(images_path) if f.endswith(\".png\") and not f.startswith(\"._\")])\n",
    "\n",
    "#     for image_file in image_files:\n",
    "#         image_path = os.path.join(images_path, image_file)\n",
    "#         mask_file = image_file.replace(\".png\", \"_Tool_Mask.png\")\n",
    "#         mask_path = os.path.join(masks_path, mask_file)\n",
    "        \n",
    "#         # print(image_path)\n",
    "#         # print(mask_path)\n",
    "\n",
    "#         if os.path.exists(mask_path):\n",
    "#             # print(f\"Processing {image_file}...\")\n",
    "#             # Load the mask image\n",
    "#             mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#             # Open the corresponding label file\n",
    "#             label_file = os.path.join(labels_path, image_file.replace(\".png\", \".txt\"))\n",
    "#             with open(label_file, \"w\") as lf:\n",
    "#                 for contour in contours:\n",
    "#                     x, y, w, h = cv2.boundingRect(contour)\n",
    "#                     # Normalize coordinates\n",
    "#                     x_center = (x + w / 2) / mask.shape[1]\n",
    "#                     y_center = (y + h / 2) / mask.shape[0]\n",
    "#                     width = w / mask.shape[1]\n",
    "#                     height = h / mask.shape[0]\n",
    "#                     # Write to label file in YOLO format\n",
    "#                     lf.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "#                 # # use matplotlib to display the images with bounding box\n",
    "#                 # image = cv2.imread(image_path)\n",
    "#                 # for contour in contours:\n",
    "#                 #     x, y, w, h = cv2.boundingRect(contour)\n",
    "#                 #     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "#                 # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#                 # plt.axis(\"off\")\n",
    "#                 # plt.show()\n",
    "\n",
    "#     print(\"Annotations created in YOLO format.\")\n",
    "\n",
    "# # Create annotations for training images\n",
    "# create_annotations(train_positive_images_path, train_masks_path, train_labels_path)\n",
    "# # Create annotations for test images\n",
    "# create_annotations(test_positive_images_path, test_masks_path, test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "# Paths to your folders\n",
    "dataset_path = \"/Volumes/Exodus/Data/ART-Net/\"\n",
    "\n",
    "train_positive_images_path = os.path.join(dataset_path, \"Train/Train_Positive\")\n",
    "train_negative_images_path = os.path.join(dataset_path, \"Train/Train_Negative\")\n",
    "train_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_Tool_Mask\")\n",
    "# train_tooltip_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_TipPoint\")\n",
    "train_labels_path = os.path.join(dataset_path, \"labels/train\")\n",
    "\n",
    "test_positive_images_path = os.path.join(dataset_path, \"Test/Test_Positive\")\n",
    "test_negative_images_path = os.path.join(dataset_path, \"Test/Test_Negative\")\n",
    "test_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_Tool_Mask\")\n",
    "# test_tooltip_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_TipPoint\")\n",
    "test_labels_path = os.path.join(dataset_path, \"labels/val\")\n",
    "\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "os.makedirs(test_labels_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to create YOLO annotations from masks\n",
    "def create_annotations(\n",
    "    images_path, masks_path, tooltip_masks_path, labels_path, n=None\n",
    "):\n",
    "    if n is not None:\n",
    "        image_files = sorted(\n",
    "            [\n",
    "                f\n",
    "                for f in os.listdir(images_path)\n",
    "                if f.endswith(\".png\") and not f.startswith(\"._\")\n",
    "            ]\n",
    "        )[:n]\n",
    "    else:\n",
    "        image_files = sorted(\n",
    "            [\n",
    "                f\n",
    "                for f in os.listdir(images_path)\n",
    "                if f.endswith(\".png\") and not f.startswith(\"._\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_path, image_file)\n",
    "        mask_file = image_file.replace(\".png\", \"_Tool_Mask.png\")\n",
    "        mask_path = os.path.join(masks_path, mask_file)\n",
    "        # tooltip_mask_file = image_file.replace(\".png\", \"_TipPoint.png\")\n",
    "        # tooltip_mask_path = os.path.join(tooltip_masks_path, tooltip_mask_file)\n",
    "\n",
    "        label_file = os.path.join(labels_path, image_file.replace(\".png\", \".txt\"))\n",
    "\n",
    "        with open(label_file, \"w\") as lf:\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                contours, _ = cv2.findContours(\n",
    "                    mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "                )\n",
    "                for contour in contours:\n",
    "                    contour = contour.squeeze()  # Remove extra dimension\n",
    "                    if len(contour.shape) == 1:  # Single point, duplicate to make a box\n",
    "                        contour = np.array([contour, contour])\n",
    "                    contour = contour.reshape(-1)\n",
    "                    normalized_contour = []\n",
    "                    for i in range(0, len(contour), 2):\n",
    "                        x = contour[i] / mask.shape[1]\n",
    "                        y = contour[i + 1] / mask.shape[0]\n",
    "                        normalized_contour.extend([x, y])\n",
    "                    lf.write(f\"0 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "\n",
    "            # if os.path.exists(tooltip_mask_path):\n",
    "            #     tooltip_mask = cv2.imread(tooltip_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            #     tooltip_contours, _ = cv2.findContours(\n",
    "            #         tooltip_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "            #     )\n",
    "            #     for contour in tooltip_contours:\n",
    "            #         contour = contour.squeeze()  # Remove extra dimension\n",
    "            #         if len(contour.shape) == 1:  # Single point, duplicate to make a box\n",
    "            #             contour = np.array([contour, contour])\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "\n",
    "\n",
    "# Create annotations for training images\n",
    "# create_annotations(\n",
    "#     train_positive_images_path,\n",
    "#     train_masks_path,\n",
    "#     train_tooltip_masks_path,\n",
    "#     train_labels_path,\n",
    "# )\n",
    "\n",
    "# # Create annotations for test images\n",
    "# create_annotations(\n",
    "#     test_positive_images_path,\n",
    "#     test_masks_path,\n",
    "#     test_tooltip_masks_path,\n",
    "#     test_labels_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "dataset_path = \"D:/Data/ART-Net/\"\n",
    "\n",
    "# Create a configuration file for YOLOv8\n",
    "config_content = f\"\"\"\n",
    "train: {dataset_path}/images/train\n",
    "val: {dataset_path}/images/val\n",
    "\n",
    "nc: 1  # number of classes\n",
    "names: ['tool']  # class names\n",
    "\"\"\"\n",
    "\n",
    "# config_content = f\"\"\"\n",
    "# train: {dataset_path}/images/train\n",
    "# val: {dataset_path}/images/val\n",
    "\n",
    "# nc: 1  # number of classes\n",
    "# names: ['tool']  # class names\n",
    "# \"\"\"\n",
    "\n",
    "config_path = os.path.join(dataset_path, \"data.yaml\")\n",
    "with open(config_path, \"w\") as file:\n",
    "    file.write(config_content)\n",
    "\n",
    "# Load a pre-trained YOLOv8 model\n",
    "model = YOLO(\"yolov8s-seg.pt\")\n",
    "\n",
    "# Train the model with only 10 images instead of the full dataset\n",
    "model.train(data=config_path, epochs=1, imgsz=640)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "metrics = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"chkpts\"):\n",
    "    os.makedirs(\"chkpts\")\n",
    "# Save the model checkpoint to a file\n",
    "chkpt = \"chkpts/yolov8s-seg-artnet.pt\"\n",
    "model.save(\"chkpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# model.train(data=config_path, epochs=50, batch_size=8, imgsz=640, resume=checkpoint)\n",
    "# Train the model for 50 more epochs but save new checkpoint to a file (and the metrics to a new file)\n",
    "model = YOLO(\"chkpts/yolov8s-semiseg-artnet.pt\")\n",
    "for i in range(50):\n",
    "    model.train(data=config_path, epochs=1, imgsz=640)\n",
    "    losses.append(model.results[\"train\"][\"total_loss\"])\n",
    "    accuracies.append(model.results[\"val\"][\"mAP\"])\n",
    "    # Save the model checkpoint to a file\n",
    "    checkpoint = model.save(f\"yolov8s-semiseg-artnet-{i+1}.pt\")\n",
    "\n",
    "# Plot the training loss and validation mAP\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies)\n",
    "plt.title(\"Validation mAP\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"mAP\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.track(\"/Volumes/Exodus/Data/6DOF 2023/Test 1/Dataset.mp4\", tracker=\"bytetrack.yaml\", save=True, show=True)\n",
    "\n",
    "results = model.track(\n",
    "    \"data/6DOF/Dataset.mp4\",\n",
    "    tracker=\"bytetrack.yaml\",\n",
    "    save=True,\n",
    "    show=True,\n",
    ")\n",
    "\n",
    "# results = model.track(\n",
    "#     \"/Volumes/Exodus/Data/EndoVis 2015/Tracking (Raw Video)/Dataset1/Video.avi\",\n",
    "#     tracker=\"bytetrack.yaml\",\n",
    "#     save=True,\n",
    "#     show=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to remove overlapping boxes using Non-Max Suppression\n",
    "def non_max_suppression(boxes, scores, iou_threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    # Compute areas of each box\n",
    "    areas = (boxes[:, 2] - boxes[:, 0] + 1) * (boxes[:, 3] - boxes[:, 1] + 1)\n",
    "    order = scores.argsort()[::-1]  # Sort by score in descending order\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if order.size == 1:\n",
    "            break\n",
    "        xx1 = np.maximum(boxes[i, 0], boxes[order[1:], 0])\n",
    "        yy1 = np.maximum(boxes[i, 1], boxes[order[1:], 1])\n",
    "        xx2 = np.minimum(boxes[i, 2], boxes[order[1:], 2])\n",
    "        yy2 = np.minimum(boxes[i, 3], boxes[order[1:], 3])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "        inter = w * h\n",
    "\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        inds = np.where(iou <= iou_threshold)[0]\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "\n",
    "\n",
    "def process_image(image_path, file, model, iou_threshold=0.3, confidence_threshold=0.5, max_boxes=2):\n",
    "    # Perform inference on a new image\n",
    "    results = model(image_path, save=False, show=False, verbose=False)\n",
    "\n",
    "    # Extract the results\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    scores = results[0].boxes.conf.cpu().numpy()\n",
    "\n",
    "    # Step 1: Filter out boxes with confidence scores less than the threshold\n",
    "    filtered_indices = np.where(scores >= confidence_threshold)[0]\n",
    "    filtered_boxes = boxes[filtered_indices]\n",
    "    filtered_scores = scores[filtered_indices]\n",
    "\n",
    "    # Step 2: Remove overlapping boxes using Non-Max Suppression\n",
    "    nms_indices = non_max_suppression(filtered_boxes, filtered_scores, iou_threshold)\n",
    "\n",
    "    # Keep only the top boxes\n",
    "    top_indices = nms_indices[:max_boxes]\n",
    "\n",
    "    # Update results with filtered boxes\n",
    "    results[0].boxes = results[0].boxes[top_indices]\n",
    "\n",
    "    # Display the results\n",
    "    # results[0].show()\n",
    "\n",
    "    # Store image in tmp\n",
    "    tmp = \"tmp/\" + file.replace(\".bmp\", \"_tmp.png\")\n",
    "    results[0].save(tmp)\n",
    "\n",
    "# test_dir = \"/Volumes/Exodus/Data/6DOF 2023/Test 1/\"\n",
    "test_dir = \"/Volumes/Exodus/Data/EndoVis 2015/Testing (Raw Images)/OP1/\"\n",
    "\n",
    "# For all bmp files\n",
    "for file in sorted(os.listdir(test_dir)):\n",
    "    if file.endswith(\".png\") and not file.startswith(\"._\"):\n",
    "        test_path = os.path.join(test_dir, file)\n",
    "        process_image(test_path, file, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "\n",
    "\n",
    "# Combine all bmp files to video\n",
    "# Create video from BMP files\n",
    "def stitch_images(bmp_directory, output_video_path):\n",
    "    # List all BMP files in the directory\n",
    "    bmp_files = sorted(\n",
    "        [\n",
    "            os.path.join(bmp_directory, f)\n",
    "            for f in os.listdir(bmp_directory)\n",
    "            if f.endswith(\".png\") and not f.startswith(\".\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create a video writer object\n",
    "    with imageio.get_writer(output_video_path, fps=24) as writer:\n",
    "        for file_path in bmp_files:\n",
    "            image = imageio.imread(file_path)\n",
    "            writer.append_data(image)\n",
    "\n",
    "    print(f\"Video saved at {output_video_path}\")\n",
    "\n",
    "\n",
    "output_image_name = \"results/Test 1/yolo8-1.mp4\"\n",
    "\n",
    "# Stitch the images together\n",
    "# stitch_images(\"tmp\", output_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use label file to draw original bounding box on original image\n",
    "sample_label = \"/Volumes/Exodus/Data/ART-Net/labels/val/Test_Pos_sample_0001.txt\"\n",
    "sample_image = (\n",
    "    \"/Volumes/Exodus/Data/ART-Net/Test/Test_Positive/Test_Pos_sample_0001.png\"\n",
    ")\n",
    "\n",
    "# Draw plot with two images, one of sample image and one with results[0]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "image = cv2.imread(sample_image)\n",
    "with open(sample_label, \"r\") as lf:\n",
    "    for line in lf:\n",
    "        label = line.strip().split(\" \")\n",
    "    x_center, y_center, width, height = map(float, label[1:])\n",
    "    image = cv2.imread(sample_image)\n",
    "    x = int((x_center - width / 2) * image.shape[1])\n",
    "    y = int((y_center - height / 2) * image.shape[0])\n",
    "    w = int(width * image.shape[1])\n",
    "    h = int(height * image.shape[0])\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# save image\n",
    "# results[0].save(\"tmp/results.png\")\n",
    "# # display image\n",
    "# plt.imshow(cv2.cvtColor(cv2.imread(\"tmp/results.png\"), cv2.COLOR_BGR2RGB))\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
