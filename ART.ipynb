{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths to your folders\n",
    "dataset_path = \"/Volumes/Exodus/Data/ART-Net/\"\n",
    "\n",
    "train_positive_images_path = os.path.join(dataset_path, \"Train/Train_Positive\")\n",
    "train_negative_images_path = os.path.join(dataset_path, \"Train/Train_Negative\")\n",
    "train_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_Tool_Mask\")\n",
    "train_labels_path = os.path.join(dataset_path, \"labels/train\")\n",
    "\n",
    "test_positive_images_path = os.path.join(dataset_path, \"Test/Test_Positive\")\n",
    "test_negative_images_path = os.path.join(dataset_path, \"Test/Test_Negative\")\n",
    "test_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_Tool_Mask\")\n",
    "test_labels_path = os.path.join(dataset_path, \"labels/val\")\n",
    "\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "os.makedirs(test_labels_path, exist_ok=True)\n",
    "\n",
    "# Function to create YOLO annotations from masks\n",
    "def create_annotations(images_path, masks_path, labels_path, n = None):\n",
    "    if n is not None:\n",
    "        image_files = sorted([f for f in os.listdir(images_path) if f.endswith(\".png\") and not f.startswith(\"._\")])[:n]\n",
    "    else:\n",
    "        image_files = sorted([f for f in os.listdir(images_path) if f.endswith(\".png\") and not f.startswith(\"._\")])\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_path, image_file)\n",
    "        mask_file = image_file.replace(\".png\", \"_Tool_Mask.png\")\n",
    "        mask_path = os.path.join(masks_path, mask_file)\n",
    "\n",
    "        # print(image_path)\n",
    "        # print(mask_path)\n",
    "\n",
    "        if os.path.exists(mask_path):\n",
    "            # print(f\"Processing {image_file}...\")\n",
    "            # Load the mask image\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Open the corresponding label file\n",
    "            label_file = os.path.join(labels_path, image_file.replace(\".png\", \".txt\"))\n",
    "            with open(label_file, \"w\") as lf:\n",
    "                for contour in contours:\n",
    "                    x, y, w, h = cv2.boundingRect(contour)\n",
    "                    # Normalize coordinates\n",
    "                    x_center = (x + w / 2) / mask.shape[1]\n",
    "                    y_center = (y + h / 2) / mask.shape[0]\n",
    "                    width = w / mask.shape[1]\n",
    "                    height = h / mask.shape[0]\n",
    "                    # Write to label file in YOLO format\n",
    "                    lf.write(f\"0 {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "                # # use matplotlib to display the images with bounding box\n",
    "                # image = cv2.imread(image_path)\n",
    "                # for contour in contours:\n",
    "                #     x, y, w, h = cv2.boundingRect(contour)\n",
    "                #     cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "                # plt.axis(\"off\")\n",
    "                # plt.show()\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "\n",
    "# Create annotations for training images\n",
    "create_annotations(train_positive_images_path, train_masks_path, train_labels_path)\n",
    "# Create annotations for test images\n",
    "create_annotations(test_positive_images_path, test_masks_path, test_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process ART-Net Data in YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import c\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the paths\n",
    "base_path = \"data 2/ART-Net/\"\n",
    "train_positive_images_path = os.path.join(base_path, \"Train/Train_Positive\")\n",
    "test_positive_images_path = os.path.join(base_path, \"Test/Test_Positive\")\n",
    "train_negative_images_path = os.path.join(base_path, \"Train/Train_Negative\")\n",
    "test_negative_images_path = os.path.join(base_path, \"Test/Test_Negative\")\n",
    "\n",
    "train_mask_path = os.path.join(base_path, \"Train/Train_Positive_Tool_Mask\")\n",
    "test_mask_path = os.path.join(base_path, \"Test/Test_Positive_Tool_Mask\")\n",
    "train_tip_mask_path = os.path.join(base_path, \"Train/Train_Positive_TipPoint\")\n",
    "test_tip_mask_path = os.path.join(base_path, \"Test/Test_Positive_TipPoint\")\n",
    "\n",
    "train_label_path = os.path.join(base_path, \"labels/train\")\n",
    "test_label_path = os.path.join(base_path, \"labels/val\")\n",
    "train_image_dest = os.path.join(base_path, \"images/train\")\n",
    "test_image_dest = os.path.join(base_path, \"images/val\")\n",
    "\n",
    "# Make sure label and image directories exist\n",
    "os.makedirs(train_label_path, exist_ok=True)\n",
    "os.makedirs(test_label_path, exist_ok=True)\n",
    "os.makedirs(train_image_dest, exist_ok=True)\n",
    "os.makedirs(test_image_dest, exist_ok=True)\n",
    "\n",
    "\n",
    "def create_bounding_box(mask):\n",
    "    # Get the indices of non-black pixels\n",
    "    non_zero_indices = np.nonzero(mask)\n",
    "    if len(non_zero_indices[0]) == 0:\n",
    "        return None\n",
    "    x_min = np.min(non_zero_indices[1])\n",
    "    y_min = np.min(non_zero_indices[0])\n",
    "    x_max = np.max(non_zero_indices[1])\n",
    "    y_max = np.max(non_zero_indices[0])\n",
    "    return x_min, y_min, x_max - x_min, y_max - y_min\n",
    "\n",
    "\n",
    "def create_yolo_label(mask_path, label_file, class_id, img_w, img_h):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        return\n",
    "    # Resize the mask to match the image size\n",
    "    mask = cv2.resize(mask, (img_w, img_h))\n",
    "    bbox = create_bounding_box(mask)\n",
    "    if bbox is None:\n",
    "        return\n",
    "    x, y, w, h = bbox\n",
    "    x_center = (x + w / 2) / img_w\n",
    "    y_center = (y + h / 2) / img_h\n",
    "    width = w / img_w\n",
    "    height = h / img_h\n",
    "    # # Plot the bounding box on image\n",
    "    # cv2.rectangle(mask, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    # cv2.imshow(\"mask\", mask)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    with open(label_file, \"a\") as f:\n",
    "        f.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "    # # Validate by plotting the bounding box on the image\n",
    "    # with open(label_file, \"r\") as f:\n",
    "    #     lines = f.readlines()\n",
    "    #     if class_id == 0:\n",
    "    #         image_path = mask_path.replace(\"_Tool_Mask\", \"\")\n",
    "    #     else:\n",
    "    #         image_path = mask_path.replace(\"_TipPoint\", \"\")\n",
    "    #     image_path = os.path.join(\"data 2/ART-Net/images/train\", os.path.basename(image_path))\n",
    "    #     image = cv2.imread(image_path)\n",
    "    #     img_h, img_w = image.shape[:2]\n",
    "    #     for line in lines:\n",
    "    #         class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "    #         x = int((x_center - width / 2) * img_w)\n",
    "    #         y = int((y_center - height / 2) * img_h)\n",
    "    #         w = int(width * img_w)\n",
    "    #         h = int(height * img_h)\n",
    "    #         cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    #     cv2.imshow(\"image\", image)\n",
    "    #     cv2.waitKey(0)\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def process_positive_images(image_dir, mask_dir, tip_mask_dir, label_dir, image_dest):\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith(\".png\"):\n",
    "            print(image_file)\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_path = os.path.join(mask_dir, image_file).replace(\n",
    "                \".png\", \"_Tool_Mask.png\"\n",
    "            )\n",
    "            tip_mask_path = os.path.join(tip_mask_dir, image_file).replace(\n",
    "                \".png\", \"_TipPoint.png\"\n",
    "            )\n",
    "            label_file = os.path.join(label_dir, image_file.replace(\".png\", \".txt\"))\n",
    "            dest_image_path = os.path.join(image_dest, image_file)\n",
    "\n",
    "            # Read the image to get its size\n",
    "            image = cv2.imread(image_path)\n",
    "            img_h, img_w = image.shape[:2]\n",
    "\n",
    "            # Copy the image file to the destination\n",
    "            os.makedirs(os.path.dirname(dest_image_path), exist_ok=True)\n",
    "            cv2.imwrite(dest_image_path, cv2.imread(image_path))\n",
    "\n",
    "            # Delete label file if it exists\n",
    "            if os.path.exists(label_file):\n",
    "                os.remove(label_file)\n",
    "\n",
    "            # Create label for tool\n",
    "            create_yolo_label(\n",
    "                mask_path, label_file, class_id=0, img_w=img_w, img_h=img_h\n",
    "            )\n",
    "\n",
    "            # Create label for tool tip\n",
    "            create_yolo_label(\n",
    "                tip_mask_path, label_file, class_id=1, img_w=img_w, img_h=img_h\n",
    "            )\n",
    "\n",
    "\n",
    "def process_negative_images(image_dir, label_dir, image_dest):\n",
    "    for image_file in os.listdir(image_dir):\n",
    "        if image_file.endswith(\".png\"):\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            label_file = os.path.join(label_dir, image_file.replace(\".png\", \".txt\"))\n",
    "            dest_image_path = os.path.join(image_dest, image_file)\n",
    "\n",
    "            # Copy the image file to the destination\n",
    "            os.makedirs(os.path.dirname(dest_image_path), exist_ok=True)\n",
    "            cv2.imwrite(dest_image_path, cv2.imread(image_path))\n",
    "\n",
    "            # Create an empty label file\n",
    "            open(label_file, \"w\").close()\n",
    "\n",
    "\n",
    "# Process all datasets\n",
    "process_positive_images(\n",
    "    train_positive_images_path,\n",
    "    train_mask_path,\n",
    "    train_tip_mask_path,\n",
    "    train_label_path,\n",
    "    train_image_dest,\n",
    ")\n",
    "process_positive_images(\n",
    "    test_positive_images_path,\n",
    "    test_mask_path,\n",
    "    test_tip_mask_path,\n",
    "    test_label_path,\n",
    "    test_image_dest,\n",
    ")\n",
    "# process_negative_images(train_negative_images_path, train_label_path, train_image_dest)\n",
    "# process_negative_images(test_negative_images_path, test_label_path, test_image_dest)\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "\n",
    "\n",
    "# Iterate over images and plot bounding boxes\n",
    "def view_bounding_boxes():\n",
    "    for image_file in os.listdir(train_image_dest):\n",
    "        if image_file.endswith(\".png\") and image_file.startswith(\"Train_Pos\"):\n",
    "            image_path = os.path.join(train_image_dest, image_file)\n",
    "            label_file = os.path.join(\n",
    "                train_label_path, image_file.replace(\".png\", \".txt\")\n",
    "            )\n",
    "            image = cv2.imread(image_path)\n",
    "            img_h, img_w = image.shape[:2]\n",
    "            with open(label_file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    class_id, x_center, y_center, width, height = map(\n",
    "                        float, line.strip().split()\n",
    "                    )\n",
    "                    x = int((x_center - width / 2) * img_w)\n",
    "                    y = int((y_center - height / 2) * img_h)\n",
    "                    w = int(width * img_w)\n",
    "                    h = int(height * img_h)\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "            cv2.imshow(\"image\", image)\n",
    "            cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation split equal to test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many images in data/ART-Net/images/test\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "path = \"data 2/ART-Net/images/test\"\n",
    "files = os.listdir(path)\n",
    "count = 0\n",
    "for file in files:\n",
    "    if file.endswith(\".png\") and \"Pos\" not in file:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "# 308 test images 154 pos and 154 neg\n",
    "# 1324 train images 662 pos and 662 neg\n",
    "\n",
    "# Define the paths\n",
    "base_path = \"data 2/ART-Net/\"\n",
    "train_positive_images_path = os.path.join(base_path, \"Train/Train_Positive\")\n",
    "test_positive_images_path = os.path.join(base_path, \"Test/Test_Positive\")\n",
    "train_negative_images_path = os.path.join(base_path, \"Train/Train_Negative\")\n",
    "test_negative_images_path = os.path.join(base_path, \"Test/Test_Negative\")\n",
    "\n",
    "train_label_path = os.path.join(base_path, \"labels/train\")\n",
    "test_label_path = os.path.join(base_path, \"labels/test\")\n",
    "train_image_dest = os.path.join(base_path, \"images/train\")\n",
    "test_image_dest = os.path.join(base_path, \"images/test\")\n",
    "\n",
    "val_image_dest = os.path.join(base_path, \"images/val\")\n",
    "val_label_dest = os.path.join(base_path, \"labels/val\")\n",
    "\n",
    "# Select 154 pos and 154 neg from train images at random to add to val images and labels folder\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "train_pos_files = os.listdir(train_positive_images_path)\n",
    "train_neg_files = os.listdir(train_negative_images_path)\n",
    "train_pos_files = random.sample(train_pos_files, 154)\n",
    "train_neg_files = random.sample(train_neg_files, 154)\n",
    "\n",
    "# Move the selected images to val images folder (and corresponding label file)\n",
    "import shutil\n",
    "\n",
    "for file in train_pos_files:\n",
    "    print(file)\n",
    "    shutil.move(\n",
    "        os.path.join(train_positive_images_path, file),\n",
    "        os.path.join(val_image_dest, file),\n",
    "    )\n",
    "    label_file = file.replace(\".png\", \".txt\")\n",
    "    shutil.move(\n",
    "        os.path.join(train_label_path, label_file),\n",
    "        os.path.join(val_label_dest, label_file),\n",
    "    )\n",
    "\n",
    "\n",
    "for file in train_neg_files:\n",
    "    print(file)\n",
    "    shutil.move(\n",
    "        os.path.join(train_negative_images_path, file),\n",
    "        os.path.join(val_image_dest, file),\n",
    "    )\n",
    "    label_file = file.replace(\".png\", \".txt\")\n",
    "    shutil.move(\n",
    "        os.path.join(train_label_path, label_file),\n",
    "        os.path.join(val_label_dest, label_file),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "# Paths to your folders\n",
    "dataset_path = \"/Volumes/Exodus/Data/ART-Net/\"\n",
    "\n",
    "train_positive_images_path = os.path.join(dataset_path, \"Train/Train_Positive\")\n",
    "train_negative_images_path = os.path.join(dataset_path, \"Train/Train_Negative\")\n",
    "train_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_Tool_Mask\")\n",
    "# train_tooltip_masks_path = os.path.join(dataset_path, \"Train/Train_Positive_TipPoint\")\n",
    "train_labels_path = os.path.join(dataset_path, \"labels/train\")\n",
    "\n",
    "test_positive_images_path = os.path.join(dataset_path, \"Test/Test_Positive\")\n",
    "test_negative_images_path = os.path.join(dataset_path, \"Test/Test_Negative\")\n",
    "test_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_Tool_Mask\")\n",
    "# test_tooltip_masks_path = os.path.join(dataset_path, \"Test/Test_Positive_TipPoint\")\n",
    "test_labels_path = os.path.join(dataset_path, \"labels/val\")\n",
    "\n",
    "os.makedirs(train_labels_path, exist_ok=True)\n",
    "os.makedirs(test_labels_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Function to create YOLO annotations from masks\n",
    "def create_annotations(\n",
    "    images_path, masks_path, tooltip_masks_path, labels_path, n=None\n",
    "):\n",
    "    if n is not None:\n",
    "        image_files = sorted(\n",
    "            [\n",
    "                f\n",
    "                for f in os.listdir(images_path)\n",
    "                if f.endswith(\".png\") and not f.startswith(\"._\")\n",
    "            ]\n",
    "        )[:n]\n",
    "    else:\n",
    "        image_files = sorted(\n",
    "            [\n",
    "                f\n",
    "                for f in os.listdir(images_path)\n",
    "                if f.endswith(\".png\") and not f.startswith(\"._\")\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(images_path, image_file)\n",
    "        mask_file = image_file.replace(\".png\", \"_Tool_Mask.png\")\n",
    "        mask_path = os.path.join(masks_path, mask_file)\n",
    "        # tooltip_mask_file = image_file.replace(\".png\", \"_TipPoint.png\")\n",
    "        # tooltip_mask_path = os.path.join(tooltip_masks_path, tooltip_mask_file)\n",
    "\n",
    "        label_file = os.path.join(labels_path, image_file.replace(\".png\", \".txt\"))\n",
    "\n",
    "        with open(label_file, \"w\") as lf:\n",
    "            if os.path.exists(mask_path):\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "                contours, _ = cv2.findContours(\n",
    "                    mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "                )\n",
    "                for contour in contours:\n",
    "                    contour = contour.squeeze()  # Remove extra dimension\n",
    "                    if len(contour.shape) == 1:  # Single point, duplicate to make a box\n",
    "                        contour = np.array([contour, contour])\n",
    "                    contour = contour.reshape(-1)\n",
    "                    normalized_contour = []\n",
    "                    for i in range(0, len(contour), 2):\n",
    "                        x = contour[i] / mask.shape[1]\n",
    "                        y = contour[i + 1] / mask.shape[0]\n",
    "                        normalized_contour.extend([x, y])\n",
    "                    lf.write(f\"0 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "\n",
    "            # if os.path.exists(tooltip_mask_path):\n",
    "            #     tooltip_mask = cv2.imread(tooltip_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            #     tooltip_contours, _ = cv2.findContours(\n",
    "            #         tooltip_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "            #     )\n",
    "            #     for contour in tooltip_contours:\n",
    "            #         contour = contour.squeeze()  # Remove extra dimension\n",
    "            #         if len(contour.shape) == 1:  # Single point, duplicate to make a box\n",
    "            #             contour = np.array([contour, contour])\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "            #         contour = contour.reshape(-1)\n",
    "            #         normalized_contour = []\n",
    "            #         for i in range(0, len(contour), 2):\n",
    "            #             x = contour[i] / tooltip_mask.shape[1]\n",
    "            #             y = contour[i + 1] / tooltip_mask.shape[0]\n",
    "            #             normalized_contour.extend([x, y])\n",
    "            #         lf.write(f\"1 {' '.join(map(str, normalized_contour))}\\n\")\n",
    "    \n",
    "            # Use matplotlib to draw the images with bounding box\n",
    "            image = cv2.imread(image_path)\n",
    "            for contour in contours:\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "            # for contour in tooltip_contours:\n",
    "            #     x, y, w, h = cv2.boundingRect(contour)\n",
    "            #     cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                \n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    print(\"Annotations created in YOLO format.\")\n",
    "\n",
    "\n",
    "# Create annotations for training images\n",
    "# create_annotations(\n",
    "#     train_positive_images_path,\n",
    "#     train_masks_path,\n",
    "#     train_tooltip_masks_path,\n",
    "#     train_labels_path,\n",
    "# )\n",
    "\n",
    "# # Create annotations for test images\n",
    "# create_annotations(\n",
    "#     test_positive_images_path,\n",
    "#     test_masks_path,\n",
    "#     test_tooltip_masks_path,\n",
    "#     test_labels_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bat\n",
    "50 epochs completed in 4.264 hours.\n",
    "\n",
    "105 epochs completed in 7.044 hours.\n",
    "\n",
    "YOLOv8x-seg summary (fused): 295 layers, 71721619 parameters, 0 gradients, 343.7 GFLOPs\n",
    "val: Scanning D:\\Data\\ART-Net\\labels\\test.cache... 154 images, 0 backgrounds, 0 corrupt: 100%|██████████| 154/154 [00:00<?, ?it/s]\n",
    "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 10/10 [00:10<00:00,  1.09s/it]\n",
    "                   all        154        768       0.99      0.201      0.316      0.286       0.99      0.201      0.318      0.274\n",
    "Speed: 0.3ms preprocess, 34.8ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
    "```\n",
    "\n",
    "```json\n",
    "test_results = {\n",
    "    \"metrics/precision(B)\": 0.9903675376519159,\n",
    "    \"metrics/recall(B)\": 0.20052083333333334,\n",
    "    \"metrics/mAP50(B)\": 0.31616375813616715,\n",
    "    \"metrics/mAP50-95(B)\": 0.2863567120717536,\n",
    "    \"metrics/precision(M)\": 0.9903675376519159,\n",
    "    \"metrics/recall(M)\": 0.20052083333333334,\n",
    "    \"metrics/mAP50(M)\": 0.3179526866586455,\n",
    "    \"metrics/mAP50-95(M)\": 0.27379489430835563,\n",
    "    \"fitness\": 0.5675480902215796,\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
