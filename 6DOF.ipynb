{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See total files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.pylab import f\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = \"H:\\\\Data\\\\6DOF\"\n",
    "data = []\n",
    "\n",
    "for folder in sorted(os.listdir(path)):  # , key=lambda x: int(x.split()[1])):\n",
    "    tmp_files = 0\n",
    "    tmp_txt_files = 0\n",
    "    tmp_bmp_files = 0\n",
    "    folder_path = os.path.join(path, folder)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        for file in os.listdir(folder_path):\n",
    "            tmp_files += 1\n",
    "            if file.endswith(\".txt\"):\n",
    "                tmp_txt_files += 1\n",
    "            elif file.endswith(\".bmp\"):\n",
    "                tmp_bmp_files += 1\n",
    "\n",
    "        # Store the results in a list\n",
    "        data.append(\n",
    "            {\n",
    "                \"Folder\": folder,\n",
    "                \"Total Files\": tmp_files,\n",
    "                \"TXT Files\": tmp_txt_files,\n",
    "                \"BMP Files\": tmp_bmp_files,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort by the folder number (extracted from the folder name)\n",
    "df[\"Folder Number\"] = df[\"Folder\"].apply(lambda x: int(x.split()[1]))\n",
    "df = df.sort_values(\"Folder Number\").drop(columns=\"Folder Number\")\n",
    "\n",
    "# Create a row with the total of each column\n",
    "df = df.append(df.sum(numeric_only=True), ignore_index=True)\n",
    "\n",
    "# Display the DataFrame to the user\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from /Volumes/Exodus/Data/6DOF 2023/Test1\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data from a text file\n",
    "\"\"\" \n",
    "Time (ms)\t169448\n",
    "Reference\t-112.9437\t180.4520\t-208.2180\t0.4736\t0.4635\t-0.5261\t0.5330\n",
    "Fenestrated\t-21.9398\t56.9237\t-295.1500\t0.0451\t0.2661\t-0.8368\t-0.4763\n",
    "Curved\t-62.3648\t51.9654\t-243.1492\t0.2314\t0.3947\t-0.7884\t0.4112\n",
    "Camera\t-75.6810\t35.3394\t-270.7886\t0.5233\t-0.3824\t-0.6371\t-0.4171\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Define the function to extract data from text files and create DataFrames for each tool\n",
    "def extract_data_from_txt_files(directory):\n",
    "    data = {\"Reference\": [], \"Fenestrated\": [], \"Curved\": [], \"Camera\": []}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                with open(filepath, \"r\") as file:\n",
    "                    lines = file.readlines()\n",
    "                    # Store time in milliseconds\n",
    "                    time = int(lines[0].split()[2])\n",
    "                    for line in lines[1:]:  # Skip the header\n",
    "                        parts = line.strip().split()\n",
    "                        if len(parts) == 8:\n",
    "                            label = parts[0]\n",
    "                            x, y, z = float(parts[1]), float(parts[2]), float(parts[3])\n",
    "                            qx, qy, qz, qw = (\n",
    "                                float(parts[4]),\n",
    "                                float(parts[5]),\n",
    "                                float(parts[6]),\n",
    "                                float(parts[7]),\n",
    "                            )\n",
    "                            data[label].append(\n",
    "                                {\n",
    "                                    \"time\": time,\n",
    "                                    \"x\": x,\n",
    "                                    \"y\": y,\n",
    "                                    \"z\": z,\n",
    "                                    \"qx\": qx,\n",
    "                                    \"qy\": qy,\n",
    "                                    \"qz\": qz,\n",
    "                                    \"qw\": qw,\n",
    "                                }\n",
    "                            )\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filepath}: {e}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_6DOF = \"data/6DOF/\"  # Path to CSV data\n",
    "DATA_PATH = \"/Volumes/Exodus/Data/6DOF 2023/\"  # Local raw data path\n",
    "RESULTS_PATH = \"results/\"  # Path to store results\n",
    "    \n",
    "if not os.path.exists(RESULTS_PATH):\n",
    "    os.makedirs(RESULTS_PATH)\n",
    "\n",
    "# Store folders which exist inside DATA_PATH\n",
    "DIRECTORIES = [f for f in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all data files\n",
    "for directory in DIRECTORIES:\n",
    "    # Remove if using more than one directory\n",
    "    # This is for testing purposes\n",
    "    DATA_PATH = DATA_PATH + directory + \"/\"\n",
    "    RESULTS_PATH = RESULTS_PATH + directory + \"/\"\n",
    "    \n",
    "    if not os.path.exists(RESULTS_PATH):\n",
    "        os.makedirs(RESULTS_PATH)\n",
    "        \n",
    "    if not os.path.exists(PATH_6DOF + directory):\n",
    "        os.makedirs(PATH_6DOF + directory)\n",
    "        \n",
    "        extracted_data = extract_data_from_txt_files(DATA_PATH)\n",
    "\n",
    "        # Convert the extracted data into pandas DataFrames\n",
    "        reference_df = pd.DataFrame(extracted_data[\"Reference\"]).sort_values(\"time\")\n",
    "        fenestrated_df = pd.DataFrame(extracted_data[\"Fenestrated\"]).sort_values(\"time\")\n",
    "        curved_df = pd.DataFrame(extracted_data[\"Curved\"]).sort_values(\"time\")\n",
    "        camera_df = pd.DataFrame(extracted_data[\"Camera\"]).sort_values(\"time\")\n",
    "\n",
    "        reference_df.to_csv(PATH_6DOF + directory + \"/reference.csv\", index=False)\n",
    "        fenestrated_df.to_csv(PATH_6DOF + directory + \"/fenestrated.csv\", index=False)\n",
    "        curved_df.to_csv(PATH_6DOF + directory + \"/curved.csv\", index=False)\n",
    "        camera_df.to_csv(PATH_6DOF + directory + \"/camera.csv\", index=False)\n",
    "        print(f\"Created data files for {directory}\")\n",
    "    else:\n",
    "        print(f\"Data files for {directory} already exist\")\n",
    "\n",
    "    # # Displaying the first few entries for verification\n",
    "    # # print(reference_df.head())\n",
    "    # # print(fenestrated_df.head())\n",
    "    # # print(curved_df.head())\n",
    "    # # print(camera_df.head())\n",
    "\n",
    "    # # Displaying the first few entries for verification\n",
    "    # print(reference_df.shape)\n",
    "    # print(fenestrated_df.shape)\n",
    "    # print(curved_df.shape)\n",
    "    # print(camera_df.shape)\n",
    "\n",
    "print(\"All data files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from CSV to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV files\n",
    "def load_data(directory, n = None):\n",
    "    if n is not None:\n",
    "        reference_df = pd.read_csv(PATH_6DOF + directory + \"/reference.csv\").head(n)\n",
    "        fenestrated_df = pd.read_csv(PATH_6DOF + directory + \"/fenestrated.csv\").head(n)\n",
    "        curved_df = pd.read_csv(PATH_6DOF + directory + \"/curved.csv\").head(n)\n",
    "        camera_df = pd.read_csv(PATH_6DOF + directory + \"/camera.csv\").head(n)\n",
    "    else:\n",
    "        reference_df = pd.read_csv(PATH_6DOF + directory + \"/reference.csv\")\n",
    "        fenestrated_df = pd.read_csv(PATH_6DOF + directory + \"/fenestrated.csv\")\n",
    "        curved_df = pd.read_csv(PATH_6DOF + directory + \"/curved.csv\")\n",
    "        camera_df = pd.read_csv(PATH_6DOF + directory + \"/camera.csv\")\n",
    "    return reference_df, fenestrated_df, curved_df, camera_df\n",
    "\n",
    "reference_df, fenestrated_df, curved_df, camera_df = load_data(\"Test 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function which will run for all the directories\n",
    "def load_all_data():\n",
    "    all_data = {}\n",
    "    for directory in DIRECTORIES:\n",
    "        reference_df, fenestrated_df, curved_df, camera_df = load_data(directory)\n",
    "        all_data[directory] = {\n",
    "            \"Reference\": reference_df,\n",
    "            \"Fenestrated\": fenestrated_df,\n",
    "            \"Curved\": curved_df,\n",
    "            \"Camera\": camera_df,\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "# data = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to run callback function on each row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_call(df, callback):\n",
    "    for test in df:\n",
    "        reference_df = df[test][\"Reference\"]\n",
    "        fenestrated_df = df[test][\"Fenestrated\"]\n",
    "        curved_df = df[test][\"Curved\"]\n",
    "        camera_df = df[test][\"Camera\"]\n",
    "        callback(reference_df, \"Reference\")\n",
    "        callback(fenestrated_df, \"Fenestrated\")\n",
    "        callback(curved_df, \"Curved\")\n",
    "        callback(camera_df, \"Camera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plots for each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Define a function to create scatter plots for x, y, and z coordinates\n",
    "def create_2d_scatter_plots(df, tool_name):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=3, subplot_titles=(\"X Coordinate\", \"Y Coordinate\", \"Z Coordinate\")\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df[\"time\"], y=df[\"x\"], mode=\"markers\", name=\"x\"), row=1, col=1\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df[\"time\"], y=df[\"y\"], mode=\"markers\", name=\"y\"), row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df[\"time\"], y=df[\"z\"], mode=\"markers\", name=\"z\"), row=1, col=3\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f\"2D Scatter Plots of {tool_name} Tool Coordinates Over Time\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Plot the data for each tool\n",
    "# all_data_call(data, create_2d_scatter_plots)\n",
    "create_2d_scatter_plots(reference_df, \"Reference\")\n",
    "create_2d_scatter_plots(fenestrated_df, \"Fenestrated\")\n",
    "create_2d_scatter_plots(curved_df, \"Curved\")\n",
    "create_2d_scatter_plots(camera_df, \"Camera\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Motion plot for each tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a combined 3D motion plot for all tools\n",
    "def create_combined_3d_motion_plot(dfs, tool_names):\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=4,\n",
    "        specs=[\n",
    "            [\n",
    "                {\"type\": \"scatter3d\"},\n",
    "                {\"type\": \"scatter3d\"},\n",
    "                {\"type\": \"scatter3d\"},\n",
    "                {\"type\": \"scatter3d\"},\n",
    "            ]\n",
    "        ],\n",
    "        subplot_titles=tool_names,\n",
    "    )\n",
    "\n",
    "    for i, (df, tool_name) in enumerate(zip(dfs, tool_names), start=1):\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=df[\"x\"],\n",
    "                y=df[\"y\"],\n",
    "                z=df[\"z\"],\n",
    "                mode=\"lines+markers\",\n",
    "                marker=dict(size=4),\n",
    "                line=dict(width=2),\n",
    "                name=tool_name,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=i,\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"3D Motion Plots of Tools\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X Position\", yaxis_title=\"Y Position\", zaxis_title=\"Z Position\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# DataFrames for each tool\n",
    "dfs = [reference_df, fenestrated_df, curved_df, camera_df]\n",
    "tool_names = [\"Reference\", \"Fenestrated\", \"Curved\", \"Camera\"]\n",
    "\n",
    "# Create the combined 3D motion plot\n",
    "create_combined_3d_motion_plot(dfs, tool_names)\n",
    "# all_data_call(data, create_combined_3d_motion_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create video from data position in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/homebrew/bin/ffmpeg\"\n",
    "\n",
    "total_frames = max(len(df) for df in [reference_df, fenestrated_df, curved_df, camera_df])\n",
    "# Get total frames from all the directories\n",
    "# total_frames = [ max(len(df) for df in [data[directory][\"Reference\"], data[directory][\"Fenestrated\"], data[directory][\"Curved\"], data[directory][\"Camera\"]) for directory in DIRECTORIES ]\n",
    "\n",
    "# Only take first 10 rows for animation\n",
    "# reference_df = reference_df.head(10)\n",
    "# fenestrated_df = fenestrated_df.head(10)\n",
    "# curved_df = curved_df.head(10)\n",
    "# camera_df = camera_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the DataFrame to add a frame column\n",
    "def preprocess_for_animation(df, _):\n",
    "    df = df.copy()\n",
    "    df[\"frame\"] = np.arange(len(df))\n",
    "    return df\n",
    "\n",
    "\n",
    "reference_df = preprocess_for_animation(reference_df)\n",
    "fenestrated_df = preprocess_for_animation(fenestrated_df)\n",
    "curved_df = preprocess_for_animation(curved_df)\n",
    "camera_df = preprocess_for_animation(camera_df)\n",
    "# all_data_call(data, preprocess_for_animation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the min and max values for each axis across all tools\n",
    "x_min = min(\n",
    "    reference_df[\"x\"].min(),\n",
    "    fenestrated_df[\"x\"].min(),\n",
    "    curved_df[\"x\"].min(),\n",
    "    camera_df[\"x\"].min(),\n",
    ")\n",
    "x_max = max(\n",
    "    reference_df[\"x\"].max(),\n",
    "    fenestrated_df[\"x\"].max(),\n",
    "    curved_df[\"x\"].max(),\n",
    "    camera_df[\"x\"].max(),\n",
    ")\n",
    "y_min = min(\n",
    "    reference_df[\"y\"].min(),\n",
    "    fenestrated_df[\"y\"].min(),\n",
    "    curved_df[\"y\"].min(),\n",
    "    camera_df[\"y\"].min(),\n",
    ")\n",
    "y_max = max(\n",
    "    reference_df[\"y\"].max(),\n",
    "    fenestrated_df[\"y\"].max(),\n",
    "    curved_df[\"y\"].max(),\n",
    "    camera_df[\"y\"].max(),\n",
    ")\n",
    "z_min = min(\n",
    "    reference_df[\"z\"].min(),\n",
    "    fenestrated_df[\"z\"].min(),\n",
    "    curved_df[\"z\"].min(),\n",
    "    camera_df[\"z\"].min(),\n",
    ")\n",
    "z_max = max(\n",
    "    reference_df[\"z\"].max(),\n",
    "    fenestrated_df[\"z\"].max(),\n",
    "    curved_df[\"z\"].max(),\n",
    "    camera_df[\"z\"].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create 3D plots and save as images\n",
    "def create_3d_plots(dfs, tool_names, save_path, dpi=300, figsize=(10, 10)):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    for k in range(total_frames):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "        for df, tool_name in zip(dfs, tool_names):\n",
    "            if k < len(df):\n",
    "                x_vals = df[\"x\"][: k + 1]\n",
    "                y_vals = df[\"y\"][: k + 1]\n",
    "                z_vals = df[\"z\"][: k + 1]\n",
    "\n",
    "                if len(x_vals) >= 3:\n",
    "                    ax.plot(\n",
    "                        x_vals[-3:],\n",
    "                        y_vals[-3:],\n",
    "                        z_vals[-3:],\n",
    "                        label=tool_name,\n",
    "                        alpha=0.2,\n",
    "                    )\n",
    "                if len(x_vals) >= 2:\n",
    "                    ax.plot(\n",
    "                        x_vals[-2:],\n",
    "                        y_vals[-2:],\n",
    "                        z_vals[-2:],\n",
    "                        label=tool_name,\n",
    "                        alpha=0.4,\n",
    "                    )\n",
    "                if len(x_vals) >= 1:\n",
    "                    ax.plot(\n",
    "                        x_vals[-1:],\n",
    "                        y_vals[-1:],\n",
    "                        z_vals[-1:],\n",
    "                        label=tool_name,\n",
    "                        alpha=1.0,\n",
    "                    )\n",
    "\n",
    "        ax.set_xlim([x_min, x_max])\n",
    "        ax.set_ylim([y_min, y_max])\n",
    "        ax.set_zlim([z_min, z_max])\n",
    "        ax.set_xlabel(\"X Position\")\n",
    "        ax.set_ylabel(\"Y Position\")\n",
    "        ax.set_zlabel(\"Z Position\")\n",
    "        ax.set_title(\"3D Motion of Tools\")\n",
    "\n",
    "        # Plot unique label names only\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique_labels = []\n",
    "        unique_handles = []\n",
    "        for i, label in enumerate(labels):\n",
    "            if label not in unique_labels:\n",
    "                unique_labels.append(label)\n",
    "                unique_handles.append(handles[i])\n",
    "        ax.legend(unique_handles, unique_labels)\n",
    "\n",
    "        plt.savefig(f\"{save_path}/frame_{k:04d}.png\", dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # print(f\"Generated frame {k}/{total_frames}\")\n",
    "\n",
    "\n",
    "# Create the 3D plots and save frames\n",
    "motion_save_path = RESULTS_PATH + \"frames\"\n",
    "dfs = [reference_df, fenestrated_df, curved_df, camera_df]\n",
    "tool_names = [\"Reference\", \"Fenestrated\", \"Curved\", \"Camera\"]\n",
    "\n",
    "# If no frames exist then create them\n",
    "if not os.path.exists(RESULTS_PATH + \"/motion_video_6DOF.mp4\"):\n",
    "    if not os.path.exists(motion_save_path):\n",
    "        os.makedirs(motion_save_path)\n",
    "    create_3d_plots(dfs, tool_names, motion_save_path, dpi=300, figsize=(10, 10))\n",
    "else:\n",
    "    print(\"Frames already exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize images helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_size = (2400, 2448)\n",
    "\n",
    "# # Resize images to fixed size\n",
    "# for image in os.listdir(save_path):\n",
    "#     if image.endswith(\".png\") and not image.startswith(\"resized_\"):\n",
    "#         img_path = os.path.join(save_path, image)\n",
    "#         img = Image.open(img_path)\n",
    "#         img = img.resize(\n",
    "#             fixed_size, Image.Resampling.LANCZOS\n",
    "#         )  # Use Image.Resampling.LANCZOS\n",
    "#         img.save(os.path.join(save_path, \"resized_\" + image))\n",
    "#         # Delete original image\n",
    "#         os.remove(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an MP4 video from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a video from images\n",
    "def create_video_from_images(image_folder, output_video_path, fps=10):    \n",
    "    images = sorted([img for img in os.listdir(image_folder) if img.endswith(\".png\")])\n",
    "    # frame = Image.open(os.path.join(image_folder, images[0]))\n",
    "    # frame_width, frame_height = frame.size\n",
    "\n",
    "    writer = imageio.get_writer(output_video_path, fps=fps)\n",
    "    for image in images:\n",
    "        img_path = os.path.join(image_folder, image)\n",
    "        writer.append_data(imageio.imread(img_path))\n",
    "\n",
    "        # Delete image\n",
    "        os.remove(img_path)\n",
    "\n",
    "    writer.close()\n",
    "    \n",
    "    # Cleanup\n",
    "    os.rmdir(image_folder)\n",
    "\n",
    "\n",
    "# Create a video from the saved frames\n",
    "output_video_path = RESULTS_PATH + \"motion_video_6DOF.mp4\"\n",
    "if not os.path.exists(output_video_path):\n",
    "    create_video_from_images(DATA_PATH, output_video_path, fps=10)\n",
    "else:\n",
    "    print(\"Video already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a video from the BMP files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omarc\\AppData\\Local\\Temp\\ipykernel_30640\\3727168553.py:28: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(file_path)\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading H:\\Data\\6DOF\\Test 1 png/2263.png: image file is truncated\n",
      "Error reading H:\\Data\\6DOF\\Test 1 png/3214.png: image file is truncated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 3.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 4.mp4\n",
      "Video saved at data/6DOF/Test 6.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 7.mp4\n",
      "Video saved at data/6DOF/Test 8.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 9.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 10.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 11.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 12.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 13.mp4\n",
      "Video saved at data/6DOF/Test 14.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 15.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 16.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 17.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 18.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 19.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 20.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 21.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 22.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 23.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved at data/6DOF/Test 24.mp4\n"
     ]
    }
   ],
   "source": [
    "from math import e\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "for i in range(1, 25):\n",
    "    if i == 5:\n",
    "        continue\n",
    "    DATA_PATH = f\"H:\\Data\\\\6DOF\\Test {i} png/\"\n",
    "    RESULTS_PATH = \"data/6DOF/\"\n",
    "\n",
    "\n",
    "    # Create video from BMP files\n",
    "    def stitch_images(bmp_directory, output_video_path):\n",
    "        # List all BMP files in the directory\n",
    "        bmp_files = [\n",
    "            os.path.join(bmp_directory, f)\n",
    "            for f in os.listdir(bmp_directory)\n",
    "            if f.endswith(\".png\") and not f.startswith(\".\")\n",
    "        ]\n",
    "        \n",
    "        # Sort based on the file name 0.png, 1.png, 2.png, ...\n",
    "        bmp_files = sorted(bmp_files, key=lambda x: int(os.path.basename(x).split(\".\")[0]))\n",
    "\n",
    "        # Create a video writer object\n",
    "        with imageio.get_writer(output_video_path, fps=24) as writer:\n",
    "            for file_path in bmp_files:\n",
    "                try:\n",
    "                    image = imageio.imread(file_path)\n",
    "                    writer.append_data(image)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        print(f\"Video saved at {output_video_path}\")\n",
    "\n",
    "\n",
    "    output_image_name = RESULTS_PATH + f\"Test {i}.mp4\"\n",
    "\n",
    "    # Stitch the images together\n",
    "    stitch_images(DATA_PATH, output_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to detect surgical tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load image\n",
    "SAMPLE_IMAGE = DATA_PATH + \"100.bmp\"\n",
    "\n",
    "image = cv2.imread(SAMPLE_IMAGE)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# Perform edge detection\n",
    "edged = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Filter contours\n",
    "filtered_contours = []\n",
    "min_contour_area = 500  # Adjust this threshold based on your requirement\n",
    "\n",
    "for contour in contours:\n",
    "    if cv2.contourArea(contour) > min_contour_area:\n",
    "        filtered_contours.append(contour)\n",
    "\n",
    "# Draw contours on the image\n",
    "contour_image = image.copy()\n",
    "cv2.drawContours(contour_image, filtered_contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Extract bounding boxes\n",
    "bounding_boxes = [cv2.boundingRect(contour) for contour in filtered_contours]\n",
    "\n",
    "# Draw bounding boxes on the image\n",
    "for x, y, w, h in bounding_boxes:\n",
    "    cv2.rectangle(contour_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Save image as png and display\n",
    "output_path = RESULTS_PATH + \"cv_contour_image.png\"\n",
    "cv2.imwrite(output_path, contour_image)\n",
    "\n",
    "# Show using matplotlib\n",
    "plt.imshow(cv2.cvtColor(contour_image, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use YOLO model for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import os\n",
    "import certifi\n",
    "from ultralytics import YOLO\n",
    "\n",
    "os.environ[\"SSL_CERT_FILE\"] = certifi.where()\n",
    "\n",
    "# Load YOLO model\n",
    "# yolo_model = torch.hub.load(\n",
    "#     \"ultralytics/yolov5\", \"yolov5l\", pretrained=True\n",
    "# )\n",
    "\n",
    "# Load pretrained YOLOv10n models\n",
    "yolo_model = YOLO(\"yolov8x-seg.pt\")\n",
    "# yolo_model = YOLO(\"yolov8x-pose.pt\")\n",
    "# yolo_model = YOLO(\"yolov8x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = yolo_model.track(\n",
    "#     \"data/6DOF/Dataset.mp4\", show=True\n",
    "# )  # Tracking with default tracker\n",
    "\n",
    "# Only track scissors\n",
    "scissors_key = None\n",
    "for key in yolo_model.names:\n",
    "    if \"scissors\" in yolo_model.names[key]:\n",
    "        scissors_key = key\n",
    "        break\n",
    "\n",
    "# Tracking\n",
    "# results = yolo_model.track(\n",
    "#     \"data/6DOF/Dataset.mp4\", tracker=\"bytetrack.yaml\", save=True, show=True\n",
    "# )  # with ByteTrack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use RCNN model for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "\n",
    "# Load Mask R-CNN model\n",
    "mask_rcnn_model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "mask_rcnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcnn_segment(image_path, output_path):\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image_tensor = F.to_tensor(image_rgb)  # Convert to tensor and normalize\n",
    "\n",
    "    # Detect tools using YOLO\n",
    "    yolo_results = yolo_model(image_rgb)\n",
    "\n",
    "    # Extract YOLO bounding boxes\n",
    "    yolo_boxes = yolo_results.xyxy[0].cpu().numpy()\n",
    "\n",
    "    # Detect tools and create masks using Mask R-CNN\n",
    "    with torch.no_grad():\n",
    "        mask_rcnn_prediction = mask_rcnn_model([image_tensor])\n",
    "\n",
    "    # Extract masks and bounding boxes\n",
    "    masks = mask_rcnn_prediction[0][\"masks\"].cpu().numpy()\n",
    "    boxes = mask_rcnn_prediction[0][\"boxes\"].cpu().numpy()\n",
    "\n",
    "    # Create a copy of the image to draw the results on\n",
    "    result_image = image.copy()\n",
    "\n",
    "    # Filter masks that extend beyond YOLO bounding boxes\n",
    "    for mask, _ in zip(masks, boxes):\n",
    "        mask_resized = cv2.resize(mask[0], (image.shape[1], image.shape[0]))\n",
    "        binary_mask = (mask_resized > 0.5).astype(\n",
    "            np.uint8\n",
    "        )  # Threshold to create binary mask\n",
    "\n",
    "        for yolo_box in yolo_boxes:\n",
    "            x1, y1, x2, y2 = map(int, yolo_box[:4])\n",
    "\n",
    "            # Create a mask for the bounding box area\n",
    "            yolo_box_mask = np.zeros_like(binary_mask)\n",
    "            yolo_box_mask[y1:y2, x1:x2] = 1\n",
    "\n",
    "            # Calculate the intersection and union of the binary mask and the YOLO bounding box mask\n",
    "            intersection = np.sum(binary_mask & yolo_box_mask)\n",
    "            union = np.sum(binary_mask | yolo_box_mask)\n",
    "\n",
    "            # If the majority of the mask is within the bounding box, retain the mask\n",
    "            if intersection / union > 0.2:\n",
    "                # Create a color overlay for the mask\n",
    "                overlay = np.zeros_like(image)\n",
    "                overlay[binary_mask == 1] = (0, 255, 0)  # Apply green color to mask\n",
    "\n",
    "                # Combine original image with overlay\n",
    "                result_image = cv2.addWeighted(result_image, 1.0, overlay, 0.5, 0)\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(result_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                break\n",
    "\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    # Show using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Test with an image\n",
    "rcnn_segment(SAMPLE_IMAGE, RESULTS_PATH + \"rcnn_segmented_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CV to detect tool shaft in bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_draw_shaft(image_path, output_path):\n",
    "    # Load and preprocess image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "    # Detect tools using YOLO\n",
    "    yolo_results = yolo_model(image_rgb)\n",
    "\n",
    "    # Extract YOLO bounding boxes\n",
    "    yolo_boxes = yolo_results.xyxy[0].cpu().numpy()\n",
    "\n",
    "    # Create a copy of the image to draw the results on\n",
    "    result_image = image.copy()\n",
    "\n",
    "    for yolo_box in yolo_boxes:\n",
    "        x1, y1, x2, y2 = map(int, yolo_box[:4])\n",
    "        roi = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert ROI to grayscale and apply edge detection\n",
    "        gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "        edged_roi = cv2.Canny(blurred_roi, 50, 150)\n",
    "\n",
    "        # Apply Hough Line Transform to find lines\n",
    "        lines = cv2.HoughLinesP(edged_roi, 1, np.pi / 180, 50, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "        if lines is not None:\n",
    "            longest_line = None\n",
    "            max_length = 0\n",
    "\n",
    "            for line in lines:\n",
    "                for x1_line, y1_line, x2_line, y2_line in line:\n",
    "                    length = np.sqrt((x2_line - x1_line) ** 2 + (y2_line - y1_line) ** 2)\n",
    "                    if length > max_length:\n",
    "                        max_length = length\n",
    "                        longest_line = (x1_line, y1_line, x2_line, y2_line)\n",
    "\n",
    "            if longest_line is not None:\n",
    "                x1_line, y1_line, x2_line, y2_line = longest_line\n",
    "\n",
    "                # Compute the line equation y = mx + c\n",
    "                if x2_line - x1_line != 0:  # Avoid division by zero\n",
    "                    m = (y2_line - y1_line) / (x2_line - x1_line)\n",
    "                    c = y1_line - m * x1_line\n",
    "\n",
    "                    # Draw the line on the original image\n",
    "                    cv2.line(result_image, (x1 + x1_line, y1 + y1_line), (x1 + x2_line, y1 + y2_line), (255, 0, 0), 2)\n",
    "\n",
    "        # Draw the bounding box on the image\n",
    "        cv2.rectangle(result_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Save and show the result image\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "\n",
    "    # Show using matplotlib\n",
    "    plt.imshow(cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "detect_and_draw_shaft(SAMPLE_IMAGE, RESULTS_PATH + \"cv_shaft_detection.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2113\n",
      "Error converting 3198.bmp in H:\\Data\\6DOF\\Test 1: image file is truncated (3786 bytes not processed)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Convert all bmp files in a directory to png\n",
    "def convert_bmp_to_png(input_dir, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # list all bmp files in the input\n",
    "    bmp_files = [\n",
    "        filename for filename in os.listdir(input_dir) if filename.endswith(\".bmp\")\n",
    "    ]\n",
    "    # list all png files in the output\n",
    "    png_files = [\n",
    "        filename for filename in os.listdir(output_dir) if filename.endswith(\".png\")\n",
    "    ]\n",
    "\n",
    "    # if png file exists with same name as bmp file, remove the bmp file\n",
    "    for filename in bmp_files:\n",
    "        if filename.replace(\".bmp\", \".png\") in png_files:\n",
    "            # remove from list\n",
    "            bmp_files.remove(filename)\n",
    "    print(len(bmp_files))\n",
    "    for filename in bmp_files:\n",
    "        try:\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, filename.replace(\".bmp\", \".png\"))\n",
    "            img = Image.open(image_path)\n",
    "            img.save(output_path)\n",
    "            # os.remove(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {filename} in {input_dir}: {e}\")\n",
    "\n",
    "\n",
    "path = \"H:\\\\Data\\\\6DOF\\\\Test \"\n",
    "# for i in range(1, 25):\n",
    "i = 1\n",
    "convert_bmp_to_png(path + str(i), path + str(i) + \" png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# output_path = \"C:/Users/omarc/OneDrive - University of Leeds/University/PhD/Omar MSc Project/Code/data/6DOF/input\"\n",
    "output_path = \"H:/Data/6DOF/input\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "total = 0\n",
    "for i in range(1, 25):\n",
    "    if i == 5 or i == 6:\n",
    "        continue\n",
    "    # Take 1 png image every 100 images and add testN_ at the start of the file name\n",
    "    # print(f\"copy {base_path}{i}/*.png {output_path}/test{i}_*.png\")\n",
    "    count = 0\n",
    "    # I only want 1 every 100 frames (i.e. when n % 100 = 1)\n",
    "    for file in os.listdir(f\"H:/Data/6DOF/Test {i} png\"):\n",
    "        # file will be 0.png, 1.png, 2.png, etc.\n",
    "        if int(file.split(\".\")[0]) % 100 == 0 and file.endswith(\".png\"):\n",
    "            # os.system(f\"xcopy H:/Data/6DOF/Test {i} png/{file} {output_path}/test{i}_{file}\")\n",
    "            # copy without os\n",
    "            with open(f\"H:/Data/6DOF/Test {i} png/{file}\", \"rb\") as f:\n",
    "                with open(f\"{output_path}/test{i}_{file}\", \"wb\") as o:\n",
    "                    o.write(f.read())\n",
    "            count += 1\n",
    "    print(f\"Test {i}: {count} images\")\n",
    "    total += count\n",
    "\n",
    "print(f\"Total: {total} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Test 1: 43 images\n",
    "    Test 2: 46 images\n",
    "    Test 3: 35 images\n",
    "    Test 4: 50 images\n",
    "    Test 7: 40 images\n",
    "    Test 8: 37 images\n",
    "    Test 9: 42 images\n",
    "    Test 10: 38 images\n",
    "    Test 11: 41 images\n",
    "    Test 12: 46 images\n",
    "    Test 13: 38 images\n",
    "    Test 14: 37 images\n",
    "    Test 15: 40 images\n",
    "    Test 16: 45 images\n",
    "    Test 17: 41 images\n",
    "    Test 18: 45 images\n",
    "    Test 19: 59 images\n",
    "    Test 20: 59 images\n",
    "    Test 21: 47 images\n",
    "    Test 22: 93 images\n",
    "    Test 23: 41 images\n",
    "    Test 24: 56 images\n",
    "    Total: 1019 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 1 every 100 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# output_path = \"C:/Users/omarc/OneDrive - University of Leeds/University/PhD/Omar MSc Project/Code/data/6DOF/input\"\n",
    "output_path = \"H:/Data/6DOF/input\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "total = 0\n",
    "for i in range(1, 25):\n",
    "    if i == 5 or i == 6:\n",
    "        continue\n",
    "    # Take 1 png image every 100 images and add testN_ at the start of the file name\n",
    "    # print(f\"copy {base_path}{i}/*.png {output_path}/test{i}_*.png\")\n",
    "    count = 0\n",
    "    # I only want 1 every 100 frames (i.e. when n % 100 = 1)\n",
    "    for file in os.listdir(f\"H:/Data/6DOF/Test {i} png\"):\n",
    "        # file will be 0.png, 1.png, 2.png, etc.\n",
    "        if int(file.split(\".\")[0]) % 100 == 0 and file.endswith(\".png\"):\n",
    "            # os.system(f\"xcopy H:/Data/6DOF/Test {i} png/{file} {output_path}/test{i}_{file}\")\n",
    "            # copy without os\n",
    "            with open(f\"H:/Data/6DOF/Test {i} png/{file}\", \"rb\") as f:\n",
    "                with open(f\"{output_path}/test{i}_{file}\", \"wb\") as o:\n",
    "                    o.write(f.read())\n",
    "            count += 1\n",
    "    print(f\"Test {i}: {count} images\")\n",
    "    total += count\n",
    "\n",
    "print(f\"Total: {total} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks for missing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "input_dir = \"data/6DOF/images/train\"\n",
    "output_dir = \"data/6DOF/labels/train\"\n",
    "\n",
    "# Inputs are pngs, outputs are txts - there are 4 extra labels in the txts i need to find\n",
    "for filename in os.listdir(output_dir):\n",
    "    # if image does not exist with same basename, print filename\n",
    "    base_filename = os.path.splitext(filename)[0]\n",
    "    png_filename = f\"{base_filename}.png\"\n",
    "    png_path = os.path.join(input_dir, png_filename)\n",
    "    if not os.path.exists(png_path):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename Files for 0000 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn import base\n",
    "\n",
    "\n",
    "def sort_files_numerically(file_list):\n",
    "    \"\"\"\n",
    "    Sort file list by the numeric value, e.g. 0.png, 1.png\n",
    "    \"\"\"\n",
    "    return sorted(file_list, key=lambda x: int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "\n",
    "def rename_files(image_dir, test):\n",
    "    image_files = sort_files_numerically(\n",
    "        [f for f in os.listdir(image_dir) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    )\n",
    "\n",
    "    for _, image_file in enumerate(image_files):\n",
    "        # Extract the file extension\n",
    "        file_ext = os.path.splitext(image_file)[1]\n",
    "        \n",
    "        # Get image number\n",
    "        i = int(re.findall(r\"\\d+\", image_file)[0])\n",
    "        \n",
    "        # Create a new image name\n",
    "        new_image_name = f\"{i:04d}{file_ext}\"\n",
    "        \n",
    "        # Use Test {i} as the prefix\n",
    "        new_image_name = f\"test{test}_{new_image_name}\"\n",
    "\n",
    "        # Rename image file\n",
    "        os.rename(\n",
    "            os.path.join(image_dir, image_file), os.path.join(image_dir, new_image_name)\n",
    "        )\n",
    "        # print(f\"Renamed {image_file} to {new_image_name} in {image_dir}.\")\n",
    "\n",
    "\n",
    "# Iterate over all specified paths and rename the files\n",
    "for i in range(1, 25):\n",
    "    image_dir = f\"H:/Data/6DOF/Test {i} png\"\n",
    "    rename_files(image_dir, i)\n",
    "\n",
    "print(\"Renaming completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
