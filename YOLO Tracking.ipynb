{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import YOLOv10\n",
    "from multiprocessing import freeze_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"x\"\n",
    "# Load the YOLOv10 model\n",
    "model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_confidence_based_on_previous_frame(boxes, confs, ids, previous_ids):\n",
    "    # Placeholder logic for adjusting confidence based on previous frame\n",
    "    # In this example, confidence is increased by 0.1 if the ID is consistent with the previous frame\n",
    "    adjusted_confs = []\n",
    "    for i, current_id in enumerate(ids):\n",
    "        if current_id in previous_ids:\n",
    "            adjusted_confs.append(\n",
    "                min(confs[i] + 0.1, 1.0)\n",
    "            )  # Increase confidence slightly\n",
    "        else:\n",
    "            adjusted_confs.append(confs[i])  # Keep confidence the same\n",
    "    return adjusted_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"Compute the intersection over union of two sets of boxes.\"\"\"\n",
    "    x1, y1 = np.maximum(bbox1[:2], bbox2[:2])\n",
    "    x2, y2 = np.minimum(bbox1[2:], bbox2[2:])\n",
    "    intersection = np.prod(np.maximum(0, [x2 - x1, y2 - y1]))\n",
    "    area1 = np.prod(bbox1[2:] - bbox1[:2])\n",
    "    area2 = np.prod(bbox2[2:] - bbox2[:2])\n",
    "    union = area1 + area2 - intersection\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, track_id, bbox, feature, max_age=30):\n",
    "        self.track_id = track_id\n",
    "        self.bbox = bbox\n",
    "        self.features = deque([feature], maxlen=100)\n",
    "        self.kf = self.create_kalman_filter(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "        self.max_age = max_age\n",
    "        self.confidence = 0\n",
    "\n",
    "    def create_kalman_filter(self, bbox):\n",
    "        \"\"\"Create a Kalman filter for tracking bounding boxes.\"\"\"\n",
    "        kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        kf.F = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 1],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.H = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.P[\n",
    "            4:, 4:\n",
    "        ] *= 1000.0  # Give high uncertainty to the unobservable initial velocities\n",
    "        kf.P *= 10.0\n",
    "        kf.R *= 0.01\n",
    "        kf.x[:4] = bbox\n",
    "        return kf\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict the next state of the track.\"\"\"\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        self.time_since_update += 1\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        return self.kf.x[:4].reshape(-1)\n",
    "\n",
    "    def update(self, bbox, feature):\n",
    "        \"\"\"Update the track with a new bounding box and feature.\"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak += 1\n",
    "        self.features.append(feature)\n",
    "        self.kf.update(bbox)\n",
    "        self.bbox = self.kf.x[:4].reshape(-1)\n",
    "        self.confidence = min(\n",
    "            1.0, self.confidence + 0.1\n",
    "        )  # Increase confidence with each successful update\n",
    "\n",
    "\n",
    "class DeepSort:\n",
    "    def __init__(\n",
    "        self, max_age=50, n_init=3, max_iou_distance=0.9, max_cosine_distance=0.5\n",
    "    ):\n",
    "        self.tracks = []\n",
    "        self.next_id = 1\n",
    "        self.max_age = max_age\n",
    "        self.n_init = n_init\n",
    "        self.max_iou_distance = max_iou_distance\n",
    "        self.max_cosine_distance = max_cosine_distance\n",
    "\n",
    "    def cosine_distance(self, features, targets):\n",
    "        \"\"\"Compute the cosine distance between features and targets.\"\"\"\n",
    "        if len(features) == 0 or len(targets) == 0:\n",
    "            return np.zeros((len(features), len(targets)))\n",
    "        features = np.array(features)\n",
    "        targets = np.array(targets)\n",
    "        return 1.0 - np.dot(features, targets.T) / (\n",
    "            np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            * np.linalg.norm(targets, axis=1, keepdims=True).T\n",
    "        )\n",
    "\n",
    "    def match(self, detections):\n",
    "        \"\"\"Match detections to existing tracks based on IOU and appearance.\"\"\"\n",
    "        if len(self.tracks) == 0:\n",
    "            return [], list(range(len(detections))), []\n",
    "\n",
    "        iou_matrix = np.zeros((len(self.tracks), len(detections)), dtype=np.float32)\n",
    "        for t, track in enumerate(self.tracks):\n",
    "            for d, detection in enumerate(detections):\n",
    "                iou_matrix[t, d] = iou(track.bbox, detection[\"bbox\"])\n",
    "\n",
    "        matched_indices = linear_sum_assignment(-iou_matrix)\n",
    "        unmatched_tracks = list(set(range(len(self.tracks))) - set(matched_indices[0]))\n",
    "        unmatched_detections = list(\n",
    "            set(range(len(detections))) - set(matched_indices[1])\n",
    "        )\n",
    "\n",
    "        return matched_indices, unmatched_tracks, unmatched_detections\n",
    "\n",
    "    def update_tracks(self, detections, frame):\n",
    "        \"\"\"Update the tracks with new detections.\"\"\"\n",
    "        matched_indices, unmatched_tracks, unmatched_detections = self.match(detections)\n",
    "\n",
    "        # Debugging print statements\n",
    "        print(\"Matched Indices: \", matched_indices)\n",
    "        print(\"Unmatched Tracks: \", unmatched_tracks)\n",
    "        print(\"Unmatched Detections: \", unmatched_detections)\n",
    "\n",
    "        for t, d in zip(*matched_indices):\n",
    "            self.tracks[t].update(detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "\n",
    "        # Create new tracks for unmatched detections\n",
    "        for d in unmatched_detections:\n",
    "            self.tracks.append(\n",
    "                Track(self.next_id, detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "            )\n",
    "            self.next_id += 1\n",
    "\n",
    "        # Remove old tracks\n",
    "        self.tracks = [t for t in self.tracks if t.time_since_update <= self.max_age]\n",
    "\n",
    "        return self.tracks\n",
    "\n",
    "\n",
    "# Use the DeepSort class with updated parameters for tracking\n",
    "deepsort = DeepSort(\n",
    "    max_age=50,  # Allow tracks to survive longer without updates\n",
    "    n_init=3,  # Require more consecutive detections to establish a track\n",
    "    max_iou_distance=0.9,  # Increase IOU threshold for matching\n",
    "    max_cosine_distance=0.5,  # Increase cosine distance threshold for matching\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import det\n",
    "\n",
    "\n",
    "def euclidean_distance(bbox1, bbox2):\n",
    "    \"\"\"Compute the Euclidean distance between the centers of two bounding boxes.\"\"\"\n",
    "    center1 = np.array([(bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2])\n",
    "    center2 = np.array([(bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2])\n",
    "    return np.linalg.norm(center1 - center2)\n",
    "\n",
    "\n",
    "def initialize_tracks(detections, max_tools=2):\n",
    "    \"\"\"Initialize tracks based on the highest confidence scores.\"\"\"\n",
    "    tracks = []\n",
    "    detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "    tools_count = 0\n",
    "    for detection in detections:\n",
    "        if tools_count < max_tools and detection[\"cls\"] == 0:  # Tool\n",
    "            tools_count += 1\n",
    "            tracks.append(\n",
    "                {\n",
    "                    \"id\": tools_count,\n",
    "                    \"bbox\": detection[\"bbox\"],\n",
    "                    \"confidence\": detection[\"conf\"],\n",
    "                    \"type\": \"tool\",\n",
    "                }\n",
    "            )\n",
    "        elif tools_count <= max_tools and detection[\"cls\"] == 1:  # Tooltip\n",
    "            # Check if the tooltip belongs to an existing tool\n",
    "            closest_tool = None\n",
    "            closest_distance = float(\"inf\")\n",
    "            for track in tracks:\n",
    "                if track[\"type\"] == \"tool\":\n",
    "                    distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "                    if distance < closest_distance:\n",
    "                        closest_distance = distance\n",
    "                        closest_tool = track\n",
    "\n",
    "            if closest_tool:\n",
    "                tracks.append(\n",
    "                    {\n",
    "                        \"id\": closest_tool[\"id\"],\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tooltip\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def match_tracks(tracks, detections, max_distance=50):\n",
    "    \"\"\"Match detections to existing tracks based on Euclidean distance.\"\"\"\n",
    "    matches = []\n",
    "    for track in tracks:\n",
    "        best_match = None\n",
    "        best_distance = max_distance\n",
    "        for detection in detections:\n",
    "            distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = detection\n",
    "        if best_match:\n",
    "            matches.append((track, best_match))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def update_tracks(tracks, detections, max_distance=50, max_tools=2):\n",
    "    \"\"\"Update the tracks with new detections.\"\"\"\n",
    "    matched_tracks = []\n",
    "    tools_tracked = 0\n",
    "    tool_ids = {track[\"id\"] for track in tracks if track[\"type\"] == \"tool\"}\n",
    "\n",
    "    for track, detection in match_tracks(tracks, detections, max_distance):\n",
    "        track[\"bbox\"] = detection[\"bbox\"]\n",
    "        track[\"confidence\"] = min(1.0, track[\"confidence\"] + 0.1)\n",
    "        matched_tracks.append(track)\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tools_tracked += 1\n",
    "\n",
    "    # Handle missing tools if fewer than max_tools are tracked\n",
    "    if tools_tracked < max_tools:\n",
    "        missing_tools = max_tools - tools_tracked\n",
    "        unmatched_detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "        for detection in unmatched_detections:\n",
    "            if detection[\"cls\"] == 0:\n",
    "                tools_tracked += 1\n",
    "                track_id = tools_tracked\n",
    "                matched_tracks.append(\n",
    "                    {\n",
    "                        \"id\": track_id,\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tool\",\n",
    "                    }\n",
    "                )\n",
    "                if tools_tracked == max_tools:\n",
    "                    break\n",
    "\n",
    "    return matched_tracks\n",
    "\n",
    "\n",
    "def penalize_and_filter_tracks(tracks):\n",
    "    \"\"\"Penalize tracks that don't meet the criteria and filter them.\"\"\"\n",
    "    final_tracks = []\n",
    "    for track in tracks:\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tooltip_exists = any(\n",
    "                t[\"type\"] == \"tooltip\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 100\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tooltip_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "        elif track[\"type\"] == \"tooltip\":\n",
    "            tool_exists = any(\n",
    "                t[\"type\"] == \"tool\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 200\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tool_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "\n",
    "    return final_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracking(model, video_path, n_init=10, max_tools=2):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = \"data/6DOF/tracked_output.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    tracks = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        count += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or count > 100:\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame, verbose=False)\n",
    "\n",
    "        # Extract the required data from results\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "        confs = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        classes = results[0].boxes.cls.cpu().numpy()  # Class IDs\n",
    "\n",
    "        detections = [{\"bbox\": box, \"conf\": conf, \"cls\": cls} for box, conf, cls in zip(boxes, confs, classes)]\n",
    "\n",
    "        if count % n_init == 0 or len(tracks) == 0:\n",
    "            # Reinitialize every n_init frames or if no tracks\n",
    "            tracks = initialize_tracks(detections, max_tools=max_tools)\n",
    "        else:\n",
    "            # Update the tracks\n",
    "            tracks = update_tracks(tracks, detections, max_tools=max_tools)\n",
    "            tracks = penalize_and_filter_tracks(tracks)\n",
    "\n",
    "        # Draw bounding boxes and labels with tracking IDs\n",
    "        for track in tracks:\n",
    "            x1, y1, x2, y2 = map(int, track[\"bbox\"])\n",
    "            label = f\"{track['type']}-{track['id']}\"\n",
    "            color = (0, 255, 0) if track[\"type\"] == \"tool\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_path):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    if os.path.isdir(input_path):\n",
    "        paths = [f for f in os.listdir(input_path)]\n",
    "        # Remove all non-image files\n",
    "        paths = sorted([f for f in paths if f.endswith((\".jpg\", \".png\"))])\n",
    "        for filename in paths:\n",
    "            img_path = os.path.join(input_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append(img)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            images.append(frame)\n",
    "        cap.release()\n",
    "    print(\"Loaded\", len(images), f\"images in {time.time()-start_time} seconds\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_and_enforce_order(frame_results, prev_tool_positions):\n",
    "    tools = []\n",
    "    tooltips = []\n",
    "    new_frame_results = []\n",
    "\n",
    "    for det in frame_results.boxes:\n",
    "        cls = int(\n",
    "            det.cls.cpu().numpy()\n",
    "        )  # Move to CPU, convert to numpy, and ensure it's an integer\n",
    "        conf = det.conf.cpu().numpy()[0]  # Move to CPU and convert to numpy\n",
    "        bbox = det.xyxy.cpu().numpy()[0]  # Move to CPU and convert to numpy\n",
    "        track_id = 1 if bbox[0] < bbox[2] / 2 else 2\n",
    "        new_det = {\"cls\": cls, \"conf\": conf, \"bbox\": bbox, \"id\": track_id}\n",
    "\n",
    "        if cls == 0:\n",
    "            tools.append(new_det)\n",
    "        elif cls == 1:\n",
    "            tooltips.append(new_det)\n",
    "\n",
    "    # For tools, take the two highest confidence detections\n",
    "    tools = sorted(tools, key=lambda x: x[\"conf\"], reverse=True)[:2]\n",
    "    # For tooltips, take the two highest confidence detections\n",
    "    tooltips = sorted(tooltips, key=lambda x: x[\"conf\"], reverse=True)[:2]\n",
    "\n",
    "    # If a tool is missing, copy the last bounding box from the previous frame\n",
    "    if len(tools) == 1 and (prev_tool_positions[\"tool1\"] is not None or prev_tool_positions[\"tool2\"] is not None):\n",
    "        # Calculate distance between the previous tools and the current tool (and append the further one into tools as it will be the missing tool)\n",
    "        try:\n",
    "            tool1_distance = np.linalg.norm(\n",
    "                np.array(tools[0][\"bbox\"]) - np.array(prev_tool_positions[\"tool1\"])\n",
    "            )\n",
    "        except:\n",
    "            tool1_distance = float(\"inf\")\n",
    "        try:\n",
    "            tool2_distance = np.linalg.norm(\n",
    "                np.array(tools[0][\"bbox\"]) - np.array(prev_tool_positions[\"tool2\"])\n",
    "            )\n",
    "        except:\n",
    "            tool2_distance = float(\"inf\")\n",
    "        if tool1_distance > tool2_distance:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "    # If no tools are detected, just copy the previous tools if exist\n",
    "    elif len(tools) == 0:\n",
    "        if prev_tool_positions[\"tool1\"] is not None:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        if prev_tool_positions[\"tool2\"] is not None:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # If a tooltip is missing, copy the last bounding box from the previous frame\n",
    "    if len(tooltips) == 1 and (prev_tool_positions[\"tooltip1\"] is not None or prev_tool_positions[\"tooltip2\"] is not None):\n",
    "        # Calculate distance between the previous tooltips and the current tooltip (and append the further one into tooltips as it will be the missing tooltip)\n",
    "        try:\n",
    "            tooltip1_distance = np.linalg.norm(\n",
    "                np.array(tooltips[0][\"bbox\"]) - np.array(prev_tool_positions[\"tooltip1\"])\n",
    "            )\n",
    "        except:\n",
    "            tooltip1_distance = float(\"inf\")\n",
    "        try:\n",
    "            tooltip2_distance = np.linalg.norm(\n",
    "                np.array(tooltips[0][\"bbox\"]) - np.array(prev_tool_positions[\"tooltip2\"])\n",
    "            )\n",
    "        except:\n",
    "            tooltip2_distance = float(\"inf\")\n",
    "        if tooltip1_distance > tooltip2_distance:            \n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "    # If no tooltips are detected, just copy the previous tooltips if exist\n",
    "    elif len(tooltips) == 0:\n",
    "        if prev_tool_positions[\"tooltip1\"] is not None:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip1conf\"] - 0.1, 0.0),    \n",
    "                    \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        if prev_tool_positions[\"tooltip2\"] is not None:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Sort tools by x-coordinate (left to right)\n",
    "    tool1_x1 = tools[0][\"bbox\"][0]\n",
    "    tool2_x1 = tools[1][\"bbox\"][0]\n",
    "    tool1_x2 = tools[0][\"bbox\"][2]\n",
    "    tool2_x2 = tools[1][\"bbox\"][2]\n",
    "\n",
    "    # Find largest difference between x1 and x2\n",
    "    if tool1_x2 - tool1_x1 > tool2_x2 - tool2_x1:\n",
    "        tools_sorted = sorted(tools, key=lambda x: x[\"bbox\"][0])\n",
    "        # Sort tooltips by same order as tools\n",
    "        tooltips = sorted(tooltips, key=lambda x: x[\"bbox\"][0])\n",
    "    else:\n",
    "        tools_sorted = sorted(tools, key=lambda x: x[\"bbox\"][2])\n",
    "        # Sort tooltips by same order as tools\n",
    "        tooltips = sorted(tooltips, key=lambda x: x[\"bbox\"][2])    \n",
    "\n",
    "    # Assign IDs and update previous positions: leftmost tool gets ID 1, rightmost tool gets ID 2\n",
    "    if len(tools_sorted) > 0:\n",
    "        tools_sorted[0][\"id\"] = 1  # Leftmost tool\n",
    "        prev_tool_positions[\"tool1\"] = tools_sorted[0][\"bbox\"]\n",
    "    if len(tools_sorted) > 1:\n",
    "        tools_sorted[1][\"id\"] = 2  # Rightmost tool\n",
    "        prev_tool_positions[\"tool2\"] = tools_sorted[1][\"bbox\"]\n",
    "\n",
    "    # Ensure no two tools/tooltips have the same ID, adjust if necessary\n",
    "    if len(tools_sorted) == 2 and tools_sorted[0][\"id\"] == tools_sorted[1][\"id\"]:\n",
    "        tools_sorted[1][\"id\"] = 2 if tools_sorted[0][\"id\"] == 1 else 1\n",
    "\n",
    "    # Assign tooltip IDs based on closest tool or previous positions\n",
    "    for tip in tooltips:\n",
    "        tip_center = np.array(\n",
    "            [\n",
    "                (tip[\"bbox\"][0] + tip[\"bbox\"][2]) / 2,\n",
    "                (tip[\"bbox\"][1] + tip[\"bbox\"][3]) / 2,\n",
    "            ]\n",
    "        )\n",
    "        best_tool_id = None\n",
    "        min_distance = float(\"inf\")\n",
    "\n",
    "        for tool_id in [1, 2]:  # Ensure we only compare with tools 1 and 2\n",
    "            tool_bbox = prev_tool_positions[f\"tool{tool_id}\"]\n",
    "            if tool_bbox is not None:\n",
    "                tool_center = np.array(\n",
    "                    [\n",
    "                        (tool_bbox[0] + tool_bbox[2]) / 2,\n",
    "                        (tool_bbox[1] + tool_bbox[3]) / 2,\n",
    "                    ]\n",
    "                )\n",
    "                distance = np.linalg.norm(tool_center - tip_center)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_tool_id = tool_id\n",
    "\n",
    "        if best_tool_id is not None:\n",
    "            tip[\"id\"] = best_tool_id\n",
    "            prev_tool_positions[f\"tooltip{best_tool_id}\"] = tip[\"bbox\"]\n",
    "            prev_tool_positions[f\"tooltip{best_tool_id}conf\"] = tip[\"conf\"]\n",
    "\n",
    "    # Again ensure no two tools/tooltips have the same ID, adjust if necessary\n",
    "    if len(tools_sorted) == 2 and tools_sorted[0][\"id\"] == tools_sorted[1][\"id\"]:\n",
    "        tools_sorted[1][\"id\"] = 2 if tools_sorted[0][\"id\"] == 1 else 1\n",
    "\n",
    "    # Combine the tools and tooltips back into the frame results\n",
    "    new_frame_results = tools_sorted + tooltips\n",
    "\n",
    "    prev_tool_positions[\"tool1\"] = tools_sorted[0][\"bbox\"] \n",
    "    prev_tool_positions[\"tool2\"] = tools_sorted[1][\"bbox\"] \n",
    "    prev_tool_positions[\"tooltip1\"] = tooltips[0][\"bbox\"] \n",
    "    prev_tool_positions[\"tooltip2\"] = tooltips[1][\"bbox\"] \n",
    "    prev_tool_positions[\"tool1conf\"] = tools_sorted[0][\"conf\"] \n",
    "    prev_tool_positions[\"tool2conf\"] = tools_sorted[1][\"conf\"] \n",
    "    prev_tool_positions[\"tooltip1conf\"] = tooltips[0][\"conf\"] \n",
    "    prev_tool_positions[\"tooltip2conf\"] = tooltips[1][\"conf\"] \n",
    "\n",
    "    return new_frame_results\n",
    "\n",
    "\n",
    "def process_input(model, input_path, output_path, images):\n",
    "    # Perform tracking on all images\n",
    "    track_start = time.time()\n",
    "    results = model.track(input_path, save=False, verbose=False, stream=True)\n",
    "    print(f\"Tracking complete in {time.time()-track_start} seconds\")\n",
    "\n",
    "    # Initialize tracking correction\n",
    "    prev_tool_positions = {\"tool1\": None, \"tool2\": None, \"tooltip1\": None, \"tooltip2\": None, \"tool1conf\": 0, \"tool2conf\": 0, \"tooltip1conf\": 0, \"tooltip2conf\": 0}\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Process each frame\n",
    "    process_time = time.time()\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for idx, frame_results in enumerate(results):\n",
    "        frame = images[idx]\n",
    "        processed_results = relabel_and_enforce_order(\n",
    "            frame_results, prev_tool_positions\n",
    "        )\n",
    "        for det in processed_results:\n",
    "            x1, y1, x2, y2 = map(int, det[\"bbox\"])\n",
    "            cls = det[\"cls\"]\n",
    "            bounding_boxes.append([cls, x1, y1, x2, y2])\n",
    "            # make conf percent\n",
    "            label = f\"{'Tool' if det['cls'] == 0 else 'Tooltip'} #{det['id']}, {det['conf']*100:.2f}%\"\n",
    "            color = (0, 255, 0) if cls == 0 else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2\n",
    "            )\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processed frame {idx+1}/{len(images)}\")\n",
    "        cv2.imwrite(os.path.join(output_path, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "\n",
    "    # Now go into the output directory and create a video\n",
    "    video_time = time.time()\n",
    "    output_video_path = os.path.join(output_path, \"output.mp4\")\n",
    "    h, w, _ = frame.shape\n",
    "    frame_files = sorted(\n",
    "        [f for f in os.listdir(output_path) if f.endswith((\".jpg\", \".png\"))]\n",
    "    )\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (w, h))\n",
    "    for frame_file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(output_path, frame_file))\n",
    "        os.remove(os.path.join(output_path, frame_file))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video saved in {time.time()-video_time} seconds in {output_video_path}\")\n",
    "\n",
    "    print(f\"Processing complete: {time.time()-process_time} seconds\")\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [\"n\", \"s\", \"m\", \"b\", \"l\", \"x\"]:\n",
    "    start_time = time.time()\n",
    "    model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\").to(device)\n",
    "    print(f\"Loaded model in {time.time()-start_time} seconds\")\n",
    "    process_input(\n",
    "        model,\n",
    "        \"data/6DOF/images/val\",\n",
    "        f\"chkpts/6DOF/v10{n}/track\",\n",
    "        load_images(\"data/6DOF/images/val\"),\n",
    "    )\n",
    "    print(\"Done with\", n, f\"in {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import color\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_with_opacity(\n",
    "    image_path, bounding_boxes, output_path, alpha_decay=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on an image with decreasing opacity for older boxes.\n",
    "\n",
    "    :param image_path: Path to the final image.\n",
    "    :param bounding_boxes: List of bounding boxes in the format [class_id, x1, y1, x2, y2].\n",
    "    :param output_path: Path to save the output image.\n",
    "    :param alpha_decay: Amount by which opacity decreases for older boxes.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    overlay = image.copy()\n",
    "\n",
    "    # Sort bounding boxes by class_id to apply opacity correctly\n",
    "    bounding_boxes.reverse()\n",
    "\n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        class_id, x1, y1, x2, y2 = box\n",
    "        if class_id == 0:\n",
    "            continue\n",
    "        alpha = 1 - i * alpha_decay\n",
    "        alpha = max(alpha, 0.01)  # Ensure a minimum opacity level\n",
    "\n",
    "        # set green\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # Draw the bounding box with reduced opacity with no fill (just the lines)\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image saved with bounding boxes at {output_path}\")\n",
    "\n",
    "# Paths\n",
    "image_path = \"data/6DOF/images/test/test5_319.png\"\n",
    "output_path = \"final_image_with_boxes.png\"\n",
    "\n",
    "# Draw the bounding boxes\n",
    "# draw_bounding_boxes_with_opacity(image_path, bounding_boxes, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
