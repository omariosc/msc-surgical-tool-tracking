{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import YOLOv10\n",
    "from multiprocessing import freeze_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv10(\n",
       "  (model): YOLOv10DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): SCDown(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=640, bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (6): C2fCIB(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x CIB(\n",
       "            (cv1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (3): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (4): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): SCDown(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=640, bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (8): C2fCIB(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x CIB(\n",
       "            (cv1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (3): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (4): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (attn): Attention(\n",
       "          (qkv): Conv(\n",
       "            (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (proj): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): Identity()\n",
       "          )\n",
       "          (pe): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C2fCIB(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x CIB(\n",
       "            (cv1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (3): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (4): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C2fCIB(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x CIB(\n",
       "            (cv1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (3): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (4): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): SCDown(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=640, bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C2fCIB(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x CIB(\n",
       "            (cv1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (3): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (4): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): v10Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (one2one_cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (one2one_cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640, bias=False)\n",
       "                (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=320, bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = \"x\"\n",
    "# Load the YOLOv10 model\n",
    "model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tooltip_to_tool(tools, tooltips):\n",
    "    tooltip_assignment = [-1] * len(tooltips)\n",
    "    for i, tooltip in enumerate(tooltips):\n",
    "        closest_tool = None\n",
    "        min_distance = float(\"inf\")\n",
    "        for j, tool in enumerate(tools):\n",
    "            # Calculate distance between tooltip and tool center\n",
    "            distance = np.linalg.norm(\n",
    "                np.array([tooltip[0], tooltip[1]]) - np.array([tool[0], tool[1]])\n",
    "            )\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_tool = j\n",
    "        tooltip_assignment[i] = closest_tool\n",
    "    return tooltip_assignment\n",
    "\n",
    "\n",
    "def increase_confidence_based_on_previous_frame(boxes, confs, ids, previous_ids):\n",
    "    # Placeholder logic for adjusting confidence based on previous frame\n",
    "    # In this example, confidence is increased by 0.1 if the ID is consistent with the previous frame\n",
    "    adjusted_confs = []\n",
    "    for i, current_id in enumerate(ids):\n",
    "        if current_id in previous_ids:\n",
    "            adjusted_confs.append(\n",
    "                min(confs[i] + 0.1, 1.0)\n",
    "            )  # Increase confidence slightly\n",
    "        else:\n",
    "            adjusted_confs.append(confs[i])  # Keep confidence the same\n",
    "    return adjusted_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"Compute the intersection over union of two sets of boxes.\"\"\"\n",
    "    x1, y1 = np.maximum(bbox1[:2], bbox2[:2])\n",
    "    x2, y2 = np.minimum(bbox1[2:], bbox2[2:])\n",
    "    intersection = np.prod(np.maximum(0, [x2 - x1, y2 - y1]))\n",
    "    area1 = np.prod(bbox1[2:] - bbox1[:2])\n",
    "    area2 = np.prod(bbox2[2:] - bbox2[:2])\n",
    "    union = area1 + area2 - intersection\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, track_id, bbox, feature, max_age=30):\n",
    "        self.track_id = track_id\n",
    "        self.bbox = bbox\n",
    "        self.features = deque([feature], maxlen=100)\n",
    "        self.kf = self.create_kalman_filter(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "        self.max_age = max_age\n",
    "        self.confidence = 0\n",
    "\n",
    "    def create_kalman_filter(self, bbox):\n",
    "        \"\"\"Create a Kalman filter for tracking bounding boxes.\"\"\"\n",
    "        kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        kf.F = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 1],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.H = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.P[\n",
    "            4:, 4:\n",
    "        ] *= 1000.0  # Give high uncertainty to the unobservable initial velocities\n",
    "        kf.P *= 10.0\n",
    "        kf.R *= 0.01\n",
    "        kf.x[:4] = bbox\n",
    "        return kf\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict the next state of the track.\"\"\"\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        self.time_since_update += 1\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        return self.kf.x[:4].reshape(-1)\n",
    "\n",
    "    def update(self, bbox, feature):\n",
    "        \"\"\"Update the track with a new bounding box and feature.\"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak += 1\n",
    "        self.features.append(feature)\n",
    "        self.kf.update(bbox)\n",
    "        self.bbox = self.kf.x[:4].reshape(-1)\n",
    "        self.confidence = min(\n",
    "            1.0, self.confidence + 0.1\n",
    "        )  # Increase confidence with each successful update\n",
    "\n",
    "\n",
    "class DeepSort:\n",
    "    def __init__(\n",
    "        self, max_age=50, n_init=3, max_iou_distance=0.9, max_cosine_distance=0.5\n",
    "    ):\n",
    "        self.tracks = []\n",
    "        self.next_id = 1\n",
    "        self.max_age = max_age\n",
    "        self.n_init = n_init\n",
    "        self.max_iou_distance = max_iou_distance\n",
    "        self.max_cosine_distance = max_cosine_distance\n",
    "\n",
    "    def cosine_distance(self, features, targets):\n",
    "        \"\"\"Compute the cosine distance between features and targets.\"\"\"\n",
    "        if len(features) == 0 or len(targets) == 0:\n",
    "            return np.zeros((len(features), len(targets)))\n",
    "        features = np.array(features)\n",
    "        targets = np.array(targets)\n",
    "        return 1.0 - np.dot(features, targets.T) / (\n",
    "            np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            * np.linalg.norm(targets, axis=1, keepdims=True).T\n",
    "        )\n",
    "\n",
    "    def match(self, detections):\n",
    "        \"\"\"Match detections to existing tracks based on IOU and appearance.\"\"\"\n",
    "        if len(self.tracks) == 0:\n",
    "            return [], list(range(len(detections))), []\n",
    "\n",
    "        iou_matrix = np.zeros((len(self.tracks), len(detections)), dtype=np.float32)\n",
    "        for t, track in enumerate(self.tracks):\n",
    "            for d, detection in enumerate(detections):\n",
    "                iou_matrix[t, d] = iou(track.bbox, detection[\"bbox\"])\n",
    "\n",
    "        matched_indices = linear_sum_assignment(-iou_matrix)\n",
    "        unmatched_tracks = list(set(range(len(self.tracks))) - set(matched_indices[0]))\n",
    "        unmatched_detections = list(\n",
    "            set(range(len(detections))) - set(matched_indices[1])\n",
    "        )\n",
    "\n",
    "        return matched_indices, unmatched_tracks, unmatched_detections\n",
    "\n",
    "    def update_tracks(self, detections, frame):\n",
    "        \"\"\"Update the tracks with new detections.\"\"\"\n",
    "        matched_indices, unmatched_tracks, unmatched_detections = self.match(detections)\n",
    "\n",
    "        # Debugging print statements\n",
    "        print(\"Matched Indices: \", matched_indices)\n",
    "        print(\"Unmatched Tracks: \", unmatched_tracks)\n",
    "        print(\"Unmatched Detections: \", unmatched_detections)\n",
    "\n",
    "        for t, d in zip(*matched_indices):\n",
    "            self.tracks[t].update(detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "\n",
    "        # Create new tracks for unmatched detections\n",
    "        for d in unmatched_detections:\n",
    "            self.tracks.append(\n",
    "                Track(self.next_id, detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "            )\n",
    "            self.next_id += 1\n",
    "\n",
    "        # Remove old tracks\n",
    "        self.tracks = [t for t in self.tracks if t.time_since_update <= self.max_age]\n",
    "\n",
    "        return self.tracks\n",
    "\n",
    "\n",
    "# Use the DeepSort class with updated parameters for tracking\n",
    "deepsort = DeepSort(\n",
    "    max_age=50,  # Allow tracks to survive longer without updates\n",
    "    n_init=3,  # Require more consecutive detections to establish a track\n",
    "    max_iou_distance=0.9,  # Increase IOU threshold for matching\n",
    "    max_cosine_distance=0.5,  # Increase cosine distance threshold for matching\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import det\n",
    "\n",
    "\n",
    "def euclidean_distance(bbox1, bbox2):\n",
    "    \"\"\"Compute the Euclidean distance between the centers of two bounding boxes.\"\"\"\n",
    "    center1 = np.array([(bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2])\n",
    "    center2 = np.array([(bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2])\n",
    "    return np.linalg.norm(center1 - center2)\n",
    "\n",
    "\n",
    "def initialize_tracks(detections, max_tools=2):\n",
    "    \"\"\"Initialize tracks based on the highest confidence scores.\"\"\"\n",
    "    tracks = []\n",
    "    detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "    tools_count = 0\n",
    "    for detection in detections:\n",
    "        if tools_count < max_tools and detection[\"cls\"] == 0:  # Tool\n",
    "            tools_count += 1\n",
    "            tracks.append(\n",
    "                {\n",
    "                    \"id\": tools_count,\n",
    "                    \"bbox\": detection[\"bbox\"],\n",
    "                    \"confidence\": detection[\"conf\"],\n",
    "                    \"type\": \"tool\",\n",
    "                }\n",
    "            )\n",
    "        elif tools_count <= max_tools and detection[\"cls\"] == 1:  # Tooltip\n",
    "            # Check if the tooltip belongs to an existing tool\n",
    "            closest_tool = None\n",
    "            closest_distance = float(\"inf\")\n",
    "            for track in tracks:\n",
    "                if track[\"type\"] == \"tool\":\n",
    "                    distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "                    if distance < closest_distance:\n",
    "                        closest_distance = distance\n",
    "                        closest_tool = track\n",
    "\n",
    "            if closest_tool:\n",
    "                tracks.append(\n",
    "                    {\n",
    "                        \"id\": closest_tool[\"id\"],\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tooltip\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def match_tracks(tracks, detections, max_distance=50):\n",
    "    \"\"\"Match detections to existing tracks based on Euclidean distance.\"\"\"\n",
    "    matches = []\n",
    "    for track in tracks:\n",
    "        best_match = None\n",
    "        best_distance = max_distance\n",
    "        for detection in detections:\n",
    "            distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = detection\n",
    "        if best_match:\n",
    "            matches.append((track, best_match))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def update_tracks(tracks, detections, max_distance=50, max_tools=2):\n",
    "    \"\"\"Update the tracks with new detections.\"\"\"\n",
    "    matched_tracks = []\n",
    "    tools_tracked = 0\n",
    "    tool_ids = {track[\"id\"] for track in tracks if track[\"type\"] == \"tool\"}\n",
    "\n",
    "    for track, detection in match_tracks(tracks, detections, max_distance):\n",
    "        track[\"bbox\"] = detection[\"bbox\"]\n",
    "        track[\"confidence\"] = min(1.0, track[\"confidence\"] + 0.1)\n",
    "        matched_tracks.append(track)\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tools_tracked += 1\n",
    "\n",
    "    # Handle missing tools if fewer than max_tools are tracked\n",
    "    if tools_tracked < max_tools:\n",
    "        missing_tools = max_tools - tools_tracked\n",
    "        unmatched_detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "        for detection in unmatched_detections:\n",
    "            if detection[\"cls\"] == 0:\n",
    "                tools_tracked += 1\n",
    "                track_id = tools_tracked\n",
    "                matched_tracks.append(\n",
    "                    {\n",
    "                        \"id\": track_id,\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tool\",\n",
    "                    }\n",
    "                )\n",
    "                if tools_tracked == max_tools:\n",
    "                    break\n",
    "\n",
    "    return matched_tracks\n",
    "\n",
    "\n",
    "def penalize_and_filter_tracks(tracks):\n",
    "    \"\"\"Penalize tracks that don't meet the criteria and filter them.\"\"\"\n",
    "    final_tracks = []\n",
    "    for track in tracks:\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tooltip_exists = any(\n",
    "                t[\"type\"] == \"tooltip\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 100\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tooltip_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "        elif track[\"type\"] == \"tooltip\":\n",
    "            tool_exists = any(\n",
    "                t[\"type\"] == \"tool\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 200\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tool_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "\n",
    "    return final_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracking(model, video_path, n_init=10, max_tools=2):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = \"data/6DOF/tracked_output.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    tracks = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        count += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or count > 100:\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame, verbose=False)\n",
    "\n",
    "        # Extract the required data from results\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "        confs = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        classes = results[0].boxes.cls.cpu().numpy()  # Class IDs\n",
    "\n",
    "        detections = [{\"bbox\": box, \"conf\": conf, \"cls\": cls} for box, conf, cls in zip(boxes, confs, classes)]\n",
    "\n",
    "        if count % n_init == 0 or len(tracks) == 0:\n",
    "            # Reinitialize every n_init frames or if no tracks\n",
    "            tracks = initialize_tracks(detections, max_tools=max_tools)\n",
    "        else:\n",
    "            # Update the tracks\n",
    "            tracks = update_tracks(tracks, detections, max_tools=max_tools)\n",
    "            tracks = penalize_and_filter_tracks(tracks)\n",
    "\n",
    "        # Draw bounding boxes and labels with tracking IDs\n",
    "        for track in tracks:\n",
    "            x1, y1, x2, y2 = map(int, track[\"bbox\"])\n",
    "            label = f\"{track['type']}-{track['id']}\"\n",
    "            color = (0, 255, 0) if track[\"type\"] == \"tool\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_tracking(model, \"data/6DOF/Dataset.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_path):\n",
    "    images = []\n",
    "    if os.path.isdir(input_path):\n",
    "        paths = [f for f in os.listdir(input_path)]\n",
    "        # sorts based on filename - test5_0.png, test5_1.png, test5_2.png, ...\n",
    "        paths.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "        for filename in paths:\n",
    "            if filename.endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
    "                img_path = os.path.join(input_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                images.append(img)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            images.append(frame)\n",
    "        cap.release()\n",
    "    return images\n",
    "\n",
    "\n",
    "def relabel_ids_based_on_distance(results, prev_tool_positions):\n",
    "    new_results = []\n",
    "    for frame_idx, frame_results in enumerate(results):\n",
    "        new_frame_results = []\n",
    "        for det in frame_results.boxes:\n",
    "            cls = det.cls.cpu().numpy()  # Move to CPU and convert to numpy\n",
    "            conf = det.conf.cpu().numpy()  # Move to CPU and convert to numpy\n",
    "            bbox = det.xyxy[0].cpu().numpy()  # Move to CPU and convert to numpy\n",
    "            if det.id is not None:\n",
    "                track_id = det.id.cpu().numpy()  # Move to CPU and convert to numpy\n",
    "            else:\n",
    "                track_id = -1  # Assign a default ID or handle the case appropriately\n",
    "\n",
    "\n",
    "            new_det = {\"cls\": cls, \"conf\": conf, \"bbox\": bbox, \"id\": track_id}\n",
    "\n",
    "            if cls == 1:  # Tooltip\n",
    "                min_distance = float(\"inf\")\n",
    "                best_tool_id = track_id\n",
    "                for tool_id, tool_bbox in prev_tool_positions.items():\n",
    "                    tool_center = np.array(\n",
    "                        [\n",
    "                            (tool_bbox[0] + tool_bbox[2]) / 2,\n",
    "                            (tool_bbox[1] + tool_bbox[3]) / 2,\n",
    "                        ]\n",
    "                    )\n",
    "                    tip_center = np.array(\n",
    "                        [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]\n",
    "                    )\n",
    "                    distance = np.linalg.norm(tool_center - tip_center)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_tool_id = tool_id\n",
    "                # Assign the tooltip ID to match the closest tool's ID\n",
    "                new_det[\"id\"] = best_tool_id\n",
    "            else:  # Tool\n",
    "                prev_tool_positions[int(track_id)] = (\n",
    "                    bbox  # Update the position of the tool\n",
    "                )\n",
    "\n",
    "            new_frame_results.append(new_det)\n",
    "        new_results.append(new_frame_results)\n",
    "    return new_results\n",
    "\n",
    "\n",
    "def enforce_id_order(results):\n",
    "    for frame_results in results:\n",
    "        tools = [det for det in frame_results if det[\"cls\"] == 0]\n",
    "        if len(tools) > 2:\n",
    "            tools = sorted(tools, key=lambda x: x[\"conf\"], reverse=True)[:2]\n",
    "        tools = sorted(\n",
    "            tools, key=lambda x: x[\"bbox\"][0]\n",
    "        )  # Sort tools by x-coordinate (left to right)\n",
    "        if len(tools) > 1:\n",
    "            tools[0][\"id\"] = 1  # Leftmost tool gets ID 1\n",
    "            tools[1][\"id\"] = 2  # Rightmost tool gets ID 2\n",
    "        elif len(tools) == 1:\n",
    "            tools[0][\"id\"] = 1  # Only one tool, assign ID 1\n",
    "\n",
    "        # Assign tooltip IDs based on closest tool\n",
    "        for det in frame_results:\n",
    "            if det[\"cls\"] == 1:  # Tooltip\n",
    "                min_distance = float(\"inf\")\n",
    "                best_tool_id = det[\"id\"]\n",
    "                for tool in tools:\n",
    "                    tool_center = np.array(\n",
    "                        [\n",
    "                            (tool[\"bbox\"][0] + tool[\"bbox\"][2]) / 2,\n",
    "                            (tool[\"bbox\"][1] + tool[\"bbox\"][3]) / 2,\n",
    "                        ]\n",
    "                    )\n",
    "                    tip_center = np.array(\n",
    "                        [\n",
    "                            (det[\"bbox\"][0] + det[\"bbox\"][2]) / 2,\n",
    "                            (det[\"bbox\"][1] + det[\"bbox\"][3]) / 2,\n",
    "                        ]\n",
    "                    )\n",
    "                    distance = np.linalg.norm(tool_center - tip_center)\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                        best_tool_id = tool[\"id\"]\n",
    "                det[\"id\"] = best_tool_id\n",
    "\n",
    "\n",
    "def process_input(model, input_path, output_path):\n",
    "    # Load images from the input path (video or directory)\n",
    "    images = load_images(input_path)\n",
    "\n",
    "    # Perform tracking on all images\n",
    "    results = model.track(images, save=False, verbose=False, stream=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Initialize tracking correction\n",
    "    prev_tool_positions = {}\n",
    "\n",
    "    # Modify the IDs based on proximity (Euclidean distance)\n",
    "    results = relabel_ids_based_on_distance(results, prev_tool_positions)\n",
    "\n",
    "    # Enforce ID order (tool on left = 1, tool on right = 2)\n",
    "    enforce_id_order(results)\n",
    "\n",
    "    # Save the processed frames\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for idx, frame_results in enumerate(results):\n",
    "        frame = images[idx]\n",
    "        for det in frame_results:\n",
    "            x1, y1, x2, y2 = map(int, det[\"bbox\"])\n",
    "            label = (\n",
    "                f\"ID: {det['id']}, Class: {'Tool' if det['cls'] == 0 else 'Tooltip'}\"\n",
    "            )\n",
    "            color = (0, 255, 0) if det[\"cls\"] == 0 else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2\n",
    "            )\n",
    "        cv2.imwrite(os.path.join(output_path, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "\n",
    "    # Now go into the output directory and create a video\n",
    "    output_video_path = os.path.join(output_path, \"output.mp4\")\n",
    "    frame_files = sorted(\n",
    "        [f for f in os.listdir(output_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "    )\n",
    "    frame = cv2.imread(os.path.join(output_path, frame_files[0]))\n",
    "    h, w, _ = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (w, h))\n",
    "    for frame_file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(output_path, frame_file))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(\"Processing complete. Frames saved in:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.36 GiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 19.86 GiB is allocated by PyTorch, and 2.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLOv10(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchkpts/6DOF/v10\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/yolov10\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-detect-6dof/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/6DOF/images/val\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprocessed_output/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with\u001b[39m\u001b[38;5;124m\"\u001b[39m, n)\n",
      "Cell \u001b[1;32mIn[43], line 121\u001b[0m, in \u001b[0;36mprocess_input\u001b[1;34m(model, input_path, output_path)\u001b[0m\n\u001b[0;32m    118\u001b[0m prev_tool_positions \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# Modify the IDs based on proximity (Euclidean distance)\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrelabel_ids_based_on_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tool_positions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Enforce ID order (tool on left = 1, tool on right = 2)\u001b[39;00m\n\u001b[0;32m    124\u001b[0m enforce_id_order(results)\n",
      "Cell \u001b[1;32mIn[43], line 25\u001b[0m, in \u001b[0;36mrelabel_ids_based_on_distance\u001b[1;34m(results, prev_tool_positions)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelabel_ids_based_on_distance\u001b[39m(results, prev_tool_positions):\n\u001b[0;32m     24\u001b[0m     new_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame_idx, frame_results \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[0;32m     26\u001b[0m         new_frame_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m det \u001b[38;5;129;01min\u001b[39;00m frame_results\u001b[38;5;241m.\u001b[39mboxes:\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\engine\\predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 248\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\autobackend.py:422\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 422\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\tasks.py:94\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\tasks.py:133\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 133\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    134\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\omarc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\modules\\block.py:233\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    231\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    232\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m--> 233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.36 GiB. GPU 0 has a total capacity of 12.00 GiB of which 0 bytes is free. Of the allocated memory 19.86 GiB is allocated by PyTorch, and 2.59 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for n in [\"n\", \"s\", \"m\", \"b\", \"l\", \"x\"]:\n",
    "    model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\").to(device)\n",
    "    process_input(model, \"data/6DOF/images/val\", f\"processed_output/{n}\")\n",
    "    print(\"Done with\", n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
