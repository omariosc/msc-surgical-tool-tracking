{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import YOLOv10\n",
    "from multiprocessing import freeze_support\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"x\"\n",
    "# Load the YOLOv10 model\n",
    "model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_confidence_based_on_previous_frame(boxes, confs, ids, previous_ids):\n",
    "    # Placeholder logic for adjusting confidence based on previous frame\n",
    "    # In this example, confidence is increased by 0.1 if the ID is consistent with the previous frame\n",
    "    adjusted_confs = []\n",
    "    for i, current_id in enumerate(ids):\n",
    "        if current_id in previous_ids:\n",
    "            adjusted_confs.append(\n",
    "                min(confs[i] + 0.1, 1.0)\n",
    "            )  # Increase confidence slightly\n",
    "        else:\n",
    "            adjusted_confs.append(confs[i])  # Keep confidence the same\n",
    "    return adjusted_confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(bbox1, bbox2):\n",
    "    \"\"\"Compute the intersection over union of two sets of boxes.\"\"\"\n",
    "    x1, y1 = np.maximum(bbox1[:2], bbox2[:2])\n",
    "    x2, y2 = np.minimum(bbox1[2:], bbox2[2:])\n",
    "    intersection = np.prod(np.maximum(0, [x2 - x1, y2 - y1]))\n",
    "    area1 = np.prod(bbox1[2:] - bbox1[:2])\n",
    "    area2 = np.prod(bbox2[2:] - bbox2[:2])\n",
    "    union = area1 + area2 - intersection\n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "\n",
    "class Track:\n",
    "    def __init__(self, track_id, bbox, feature, max_age=30):\n",
    "        self.track_id = track_id\n",
    "        self.bbox = bbox\n",
    "        self.features = deque([feature], maxlen=100)\n",
    "        self.kf = self.create_kalman_filter(bbox)\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak = 0\n",
    "        self.age = 0\n",
    "        self.max_age = max_age\n",
    "        self.confidence = 0\n",
    "\n",
    "    def create_kalman_filter(self, bbox):\n",
    "        \"\"\"Create a Kalman filter for tracking bounding boxes.\"\"\"\n",
    "        kf = KalmanFilter(dim_x=7, dim_z=4)\n",
    "        kf.F = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 1, 0, 0, 0, 1],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 1, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 1, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.H = np.array(\n",
    "            [\n",
    "                [1, 0, 0, 0, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0, 0],\n",
    "                [0, 0, 0, 1, 0, 0, 0],\n",
    "                [0, 0, 0, 0, 0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        kf.P[\n",
    "            4:, 4:\n",
    "        ] *= 1000.0  # Give high uncertainty to the unobservable initial velocities\n",
    "        kf.P *= 10.0\n",
    "        kf.R *= 0.01\n",
    "        kf.x[:4] = bbox\n",
    "        return kf\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"Predict the next state of the track.\"\"\"\n",
    "        self.kf.predict()\n",
    "        self.age += 1\n",
    "        self.time_since_update += 1\n",
    "        if self.time_since_update > 0:\n",
    "            self.hit_streak = 0\n",
    "        return self.kf.x[:4].reshape(-1)\n",
    "\n",
    "    def update(self, bbox, feature):\n",
    "        \"\"\"Update the track with a new bounding box and feature.\"\"\"\n",
    "        self.time_since_update = 0\n",
    "        self.hit_streak += 1\n",
    "        self.features.append(feature)\n",
    "        self.kf.update(bbox)\n",
    "        self.bbox = self.kf.x[:4].reshape(-1)\n",
    "        self.confidence = min(\n",
    "            1.0, self.confidence + 0.1\n",
    "        )  # Increase confidence with each successful update\n",
    "\n",
    "\n",
    "class DeepSort:\n",
    "    def __init__(\n",
    "        self, max_age=50, n_init=3, max_iou_distance=0.9, max_cosine_distance=0.5\n",
    "    ):\n",
    "        self.tracks = []\n",
    "        self.next_id = 1\n",
    "        self.max_age = max_age\n",
    "        self.n_init = n_init\n",
    "        self.max_iou_distance = max_iou_distance\n",
    "        self.max_cosine_distance = max_cosine_distance\n",
    "\n",
    "    def cosine_distance(self, features, targets):\n",
    "        \"\"\"Compute the cosine distance between features and targets.\"\"\"\n",
    "        if len(features) == 0 or len(targets) == 0:\n",
    "            return np.zeros((len(features), len(targets)))\n",
    "        features = np.array(features)\n",
    "        targets = np.array(targets)\n",
    "        return 1.0 - np.dot(features, targets.T) / (\n",
    "            np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            * np.linalg.norm(targets, axis=1, keepdims=True).T\n",
    "        )\n",
    "\n",
    "    def match(self, detections):\n",
    "        \"\"\"Match detections to existing tracks based on IOU and appearance.\"\"\"\n",
    "        if len(self.tracks) == 0:\n",
    "            return [], list(range(len(detections))), []\n",
    "\n",
    "        iou_matrix = np.zeros((len(self.tracks), len(detections)), dtype=np.float32)\n",
    "        for t, track in enumerate(self.tracks):\n",
    "            for d, detection in enumerate(detections):\n",
    "                iou_matrix[t, d] = iou(track.bbox, detection[\"bbox\"])\n",
    "\n",
    "        matched_indices = linear_sum_assignment(-iou_matrix)\n",
    "        unmatched_tracks = list(set(range(len(self.tracks))) - set(matched_indices[0]))\n",
    "        unmatched_detections = list(\n",
    "            set(range(len(detections))) - set(matched_indices[1])\n",
    "        )\n",
    "\n",
    "        return matched_indices, unmatched_tracks, unmatched_detections\n",
    "\n",
    "    def update_tracks(self, detections, frame):\n",
    "        \"\"\"Update the tracks with new detections.\"\"\"\n",
    "        matched_indices, unmatched_tracks, unmatched_detections = self.match(detections)\n",
    "\n",
    "        # Debugging print statements\n",
    "        print(\"Matched Indices: \", matched_indices)\n",
    "        print(\"Unmatched Tracks: \", unmatched_tracks)\n",
    "        print(\"Unmatched Detections: \", unmatched_detections)\n",
    "\n",
    "        for t, d in zip(*matched_indices):\n",
    "            self.tracks[t].update(detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "\n",
    "        # Create new tracks for unmatched detections\n",
    "        for d in unmatched_detections:\n",
    "            self.tracks.append(\n",
    "                Track(self.next_id, detections[d][\"bbox\"], detections[d][\"feature\"])\n",
    "            )\n",
    "            self.next_id += 1\n",
    "\n",
    "        # Remove old tracks\n",
    "        self.tracks = [t for t in self.tracks if t.time_since_update <= self.max_age]\n",
    "\n",
    "        return self.tracks\n",
    "\n",
    "\n",
    "# Use the DeepSort class with updated parameters for tracking\n",
    "deepsort = DeepSort(\n",
    "    max_age=50,  # Allow tracks to survive longer without updates\n",
    "    n_init=3,  # Require more consecutive detections to establish a track\n",
    "    max_iou_distance=0.9,  # Increase IOU threshold for matching\n",
    "    max_cosine_distance=0.5,  # Increase cosine distance threshold for matching\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import det\n",
    "\n",
    "\n",
    "def euclidean_distance(bbox1, bbox2):\n",
    "    \"\"\"Compute the Euclidean distance between the centers of two bounding boxes.\"\"\"\n",
    "    center1 = np.array([(bbox1[0] + bbox1[2]) / 2, (bbox1[1] + bbox1[3]) / 2])\n",
    "    center2 = np.array([(bbox2[0] + bbox2[2]) / 2, (bbox2[1] + bbox2[3]) / 2])\n",
    "    return np.linalg.norm(center1 - center2)\n",
    "\n",
    "\n",
    "def initialize_tracks(detections, max_tools=2):\n",
    "    \"\"\"Initialize tracks based on the highest confidence scores.\"\"\"\n",
    "    tracks = []\n",
    "    detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "    tools_count = 0\n",
    "    for detection in detections:\n",
    "        if tools_count < max_tools and detection[\"cls\"] == 0:  # Tool\n",
    "            tools_count += 1\n",
    "            tracks.append(\n",
    "                {\n",
    "                    \"id\": tools_count,\n",
    "                    \"bbox\": detection[\"bbox\"],\n",
    "                    \"confidence\": detection[\"conf\"],\n",
    "                    \"type\": \"tool\",\n",
    "                }\n",
    "            )\n",
    "        elif tools_count <= max_tools and detection[\"cls\"] == 1:  # Tooltip\n",
    "            # Check if the tooltip belongs to an existing tool\n",
    "            closest_tool = None\n",
    "            closest_distance = float(\"inf\")\n",
    "            for track in tracks:\n",
    "                if track[\"type\"] == \"tool\":\n",
    "                    distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "                    if distance < closest_distance:\n",
    "                        closest_distance = distance\n",
    "                        closest_tool = track\n",
    "\n",
    "            if closest_tool:\n",
    "                tracks.append(\n",
    "                    {\n",
    "                        \"id\": closest_tool[\"id\"],\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tooltip\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return tracks\n",
    "\n",
    "\n",
    "def match_tracks(tracks, detections, max_distance=50):\n",
    "    \"\"\"Match detections to existing tracks based on Euclidean distance.\"\"\"\n",
    "    matches = []\n",
    "    for track in tracks:\n",
    "        best_match = None\n",
    "        best_distance = max_distance\n",
    "        for detection in detections:\n",
    "            distance = euclidean_distance(track[\"bbox\"], detection[\"bbox\"])\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = detection\n",
    "        if best_match:\n",
    "            matches.append((track, best_match))\n",
    "    return matches\n",
    "\n",
    "\n",
    "def update_tracks(tracks, detections, max_distance=50, max_tools=2):\n",
    "    \"\"\"Update the tracks with new detections.\"\"\"\n",
    "    matched_tracks = []\n",
    "    tools_tracked = 0\n",
    "    tool_ids = {track[\"id\"] for track in tracks if track[\"type\"] == \"tool\"}\n",
    "\n",
    "    for track, detection in match_tracks(tracks, detections, max_distance):\n",
    "        track[\"bbox\"] = detection[\"bbox\"]\n",
    "        track[\"confidence\"] = min(1.0, track[\"confidence\"] + 0.1)\n",
    "        matched_tracks.append(track)\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tools_tracked += 1\n",
    "\n",
    "    # Handle missing tools if fewer than max_tools are tracked\n",
    "    if tools_tracked < max_tools:\n",
    "        missing_tools = max_tools - tools_tracked\n",
    "        unmatched_detections = sorted(detections, key=lambda x: x[\"conf\"], reverse=True)\n",
    "        for detection in unmatched_detections:\n",
    "            if detection[\"cls\"] == 0:\n",
    "                tools_tracked += 1\n",
    "                track_id = tools_tracked\n",
    "                matched_tracks.append(\n",
    "                    {\n",
    "                        \"id\": track_id,\n",
    "                        \"bbox\": detection[\"bbox\"],\n",
    "                        \"confidence\": detection[\"conf\"],\n",
    "                        \"type\": \"tool\",\n",
    "                    }\n",
    "                )\n",
    "                if tools_tracked == max_tools:\n",
    "                    break\n",
    "\n",
    "    return matched_tracks\n",
    "\n",
    "\n",
    "def penalize_and_filter_tracks(tracks):\n",
    "    \"\"\"Penalize tracks that don't meet the criteria and filter them.\"\"\"\n",
    "    final_tracks = []\n",
    "    for track in tracks:\n",
    "        if track[\"type\"] == \"tool\":\n",
    "            tooltip_exists = any(\n",
    "                t[\"type\"] == \"tooltip\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 100\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tooltip_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "        elif track[\"type\"] == \"tooltip\":\n",
    "            tool_exists = any(\n",
    "                t[\"type\"] == \"tool\"\n",
    "                and t[\"id\"] == track[\"id\"]\n",
    "                and euclidean_distance(t[\"bbox\"], track[\"bbox\"]) < 200\n",
    "                for t in tracks\n",
    "            )\n",
    "            if tool_exists:\n",
    "                final_tracks.append(track)\n",
    "            else:\n",
    "                track[\"confidence\"] = max(0, track[\"confidence\"] - 0.2)\n",
    "                if track[\"confidence\"] > 0.2:\n",
    "                    final_tracks.append(track)\n",
    "\n",
    "    return final_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracking(model, video_path, n_init=10, max_tools=2):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    output_path = \"data/6DOF/tracked_output.mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    tracks = []\n",
    "    count = 0\n",
    "    while cap.isOpened():\n",
    "        count += 1\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or count > 100:\n",
    "            break\n",
    "\n",
    "        # Perform inference\n",
    "        results = model(frame, verbose=False)\n",
    "\n",
    "        # Extract the required data from results\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()  # Bounding boxes\n",
    "        confs = results[0].boxes.conf.cpu().numpy()  # Confidence scores\n",
    "        classes = results[0].boxes.cls.cpu().numpy()  # Class IDs\n",
    "\n",
    "        detections = [{\"bbox\": box, \"conf\": conf, \"cls\": cls} for box, conf, cls in zip(boxes, confs, classes)]\n",
    "\n",
    "        if count % n_init == 0 or len(tracks) == 0:\n",
    "            # Reinitialize every n_init frames or if no tracks\n",
    "            tracks = initialize_tracks(detections, max_tools=max_tools)\n",
    "        else:\n",
    "            # Update the tracks\n",
    "            tracks = update_tracks(tracks, detections, max_tools=max_tools)\n",
    "            tracks = penalize_and_filter_tracks(tracks)\n",
    "\n",
    "        # Draw bounding boxes and labels with tracking IDs\n",
    "        for track in tracks:\n",
    "            x1, y1, x2, y2 = map(int, track[\"bbox\"])\n",
    "            label = f\"{track['type']}-{track['id']}\"\n",
    "            color = (0, 255, 0) if track[\"type\"] == \"tool\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                label,\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                color,\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_path):\n",
    "    start_time = time.time()\n",
    "    images = []\n",
    "    if os.path.isdir(input_path):\n",
    "        paths = [f for f in os.listdir(input_path)]\n",
    "        # Remove all non-image files\n",
    "        paths = sorted([f for f in paths if f.endswith((\".jpg\", \".png\"))])\n",
    "        for filename in paths:\n",
    "            img_path = os.path.join(input_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append(img)\n",
    "    else:\n",
    "        cap = cv2.VideoCapture(input_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            images.append(frame)\n",
    "        cap.release()\n",
    "    print(\"Loaded\", len(images), f\"images in {time.time()-start_time} seconds\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel_and_enforce_order(frame_results, prev_tool_positions):\n",
    "    tools = []\n",
    "    tooltips = []\n",
    "    new_frame_results = []\n",
    "\n",
    "    for det in frame_results.boxes:\n",
    "        cls = int(\n",
    "            det.cls.cpu().numpy()\n",
    "        )  # Move to CPU, convert to numpy, and ensure it's an integer\n",
    "        conf = det.conf.cpu().numpy()[0]  # Move to CPU and convert to numpy\n",
    "        bbox = det.xyxy.cpu().numpy()[0]  # Move to CPU and convert to numpy\n",
    "        track_id = 1 if bbox[0] < bbox[2] / 2 else 2\n",
    "        new_det = {\"cls\": cls, \"conf\": conf, \"bbox\": bbox, \"id\": track_id}\n",
    "\n",
    "        if cls == 0:\n",
    "            tools.append(new_det)\n",
    "        elif cls == 1:\n",
    "            tooltips.append(new_det)\n",
    "\n",
    "    # For tools, take the two highest confidence detections\n",
    "    tools = sorted(tools, key=lambda x: x[\"conf\"], reverse=True)[:2]\n",
    "    # For tooltips, take the two highest confidence detections\n",
    "    tooltips = sorted(tooltips, key=lambda x: x[\"conf\"], reverse=True)[:2]\n",
    "\n",
    "    # If a tool is missing, copy the last bounding box from the previous frame\n",
    "    if len(tools) == 1 and (prev_tool_positions[\"tool1\"] is not None or prev_tool_positions[\"tool2\"] is not None):\n",
    "        # Calculate distance between the previous tools and the current tool (and append the further one into tools as it will be the missing tool)\n",
    "        try:\n",
    "            tool1_distance = np.linalg.norm(\n",
    "                np.array(tools[0][\"bbox\"]) - np.array(prev_tool_positions[\"tool1\"])\n",
    "            )\n",
    "        except:\n",
    "            tool1_distance = float(\"inf\")\n",
    "        try:\n",
    "            tool2_distance = np.linalg.norm(\n",
    "                np.array(tools[0][\"bbox\"]) - np.array(prev_tool_positions[\"tool2\"])\n",
    "            )\n",
    "        except:\n",
    "            tool2_distance = float(\"inf\")\n",
    "        if tool1_distance > tool2_distance:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "    # If no tools are detected, just copy the previous tools if exist\n",
    "    elif len(tools) == 0:\n",
    "        if prev_tool_positions[\"tool1\"] is not None:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        if prev_tool_positions[\"tool2\"] is not None:\n",
    "            tools.append(\n",
    "                {\n",
    "                    \"cls\": 0,\n",
    "                    \"conf\": max(prev_tool_positions[\"tool2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # If a tooltip is missing, copy the last bounding box from the previous frame\n",
    "    if len(tooltips) == 1 and (prev_tool_positions[\"tooltip1\"] is not None or prev_tool_positions[\"tooltip2\"] is not None):\n",
    "        # Calculate distance between the previous tooltips and the current tooltip (and append the further one into tooltips as it will be the missing tooltip)\n",
    "        try:\n",
    "            tooltip1_distance = np.linalg.norm(\n",
    "                np.array(tooltips[0][\"bbox\"]) - np.array(prev_tool_positions[\"tooltip1\"])\n",
    "            )\n",
    "        except:\n",
    "            tooltip1_distance = float(\"inf\")\n",
    "        try:\n",
    "            tooltip2_distance = np.linalg.norm(\n",
    "                np.array(tooltips[0][\"bbox\"]) - np.array(prev_tool_positions[\"tooltip2\"])\n",
    "            )\n",
    "        except:\n",
    "            tooltip2_distance = float(\"inf\")\n",
    "        if tooltip1_distance > tooltip2_distance:            \n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip1conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "    # If no tooltips are detected, just copy the previous tooltips if exist\n",
    "    elif len(tooltips) == 0:\n",
    "        if prev_tool_positions[\"tooltip1\"] is not None:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip1conf\"] - 0.1, 0.0),    \n",
    "                    \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                    \"id\": 1,\n",
    "                }\n",
    "            )\n",
    "        if prev_tool_positions[\"tooltip2\"] is not None:\n",
    "            tooltips.append(\n",
    "                {\n",
    "                    \"cls\": 1,\n",
    "                    \"conf\": max(prev_tool_positions[\"tooltip2conf\"] - 0.1, 0.0),\n",
    "                    \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                    \"id\": 2,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Sort tools by x-coordinate (left to right)\n",
    "    tool1_x1 = tools[0][\"bbox\"][0]\n",
    "    tool2_x1 = tools[1][\"bbox\"][0]\n",
    "    tool1_x2 = tools[0][\"bbox\"][2]\n",
    "    tool2_x2 = tools[1][\"bbox\"][2]\n",
    "\n",
    "    # Find largest difference between x1 and x2\n",
    "    if tool1_x2 - tool1_x1 > tool2_x2 - tool2_x1:\n",
    "        tools_sorted = sorted(tools, key=lambda x: x[\"bbox\"][0])\n",
    "        # Sort tooltips by same order as tools\n",
    "        tooltips = sorted(tooltips, key=lambda x: x[\"bbox\"][0])\n",
    "    else:\n",
    "        tools_sorted = sorted(tools, key=lambda x: x[\"bbox\"][2])\n",
    "        # Sort tooltips by same order as tools\n",
    "        tooltips = sorted(tooltips, key=lambda x: x[\"bbox\"][2])    \n",
    "\n",
    "    # Assign IDs and update previous positions: leftmost tool gets ID 1, rightmost tool gets ID 2\n",
    "    if len(tools_sorted) > 0:\n",
    "        tools_sorted[0][\"id\"] = 1  # Leftmost tool\n",
    "        prev_tool_positions[\"tool1\"] = tools_sorted[0][\"bbox\"]\n",
    "    if len(tools_sorted) > 1:\n",
    "        tools_sorted[1][\"id\"] = 2  # Rightmost tool\n",
    "        prev_tool_positions[\"tool2\"] = tools_sorted[1][\"bbox\"]\n",
    "\n",
    "    # Ensure no two tools/tooltips have the same ID, adjust if necessary\n",
    "    if len(tools_sorted) == 2 and tools_sorted[0][\"id\"] == tools_sorted[1][\"id\"]:\n",
    "        tools_sorted[1][\"id\"] = 2 if tools_sorted[0][\"id\"] == 1 else 1\n",
    "\n",
    "    # Assign tooltip IDs based on closest tool or previous positions\n",
    "    for tip in tooltips:\n",
    "        tip_center = np.array(\n",
    "            [\n",
    "                (tip[\"bbox\"][0] + tip[\"bbox\"][2]) / 2,\n",
    "                (tip[\"bbox\"][1] + tip[\"bbox\"][3]) / 2,\n",
    "            ]\n",
    "        )\n",
    "        best_tool_id = None\n",
    "        min_distance = float(\"inf\")\n",
    "\n",
    "        for tool_id in [1, 2]:  # Ensure we only compare with tools 1 and 2\n",
    "            tool_bbox = prev_tool_positions[f\"tool{tool_id}\"]\n",
    "            if tool_bbox is not None:\n",
    "                tool_center = np.array(\n",
    "                    [\n",
    "                        (tool_bbox[0] + tool_bbox[2]) / 2,\n",
    "                        (tool_bbox[1] + tool_bbox[3]) / 2,\n",
    "                    ]\n",
    "                )\n",
    "                distance = np.linalg.norm(tool_center - tip_center)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_tool_id = tool_id\n",
    "\n",
    "        if best_tool_id is not None:\n",
    "            tip[\"id\"] = best_tool_id\n",
    "            prev_tool_positions[f\"tooltip{best_tool_id}\"] = tip[\"bbox\"]\n",
    "            prev_tool_positions[f\"tooltip{best_tool_id}conf\"] = tip[\"conf\"]\n",
    "\n",
    "    # Again ensure no two tools/tooltips have the same ID, adjust if necessary\n",
    "    if len(tools_sorted) == 2 and tools_sorted[0][\"id\"] == tools_sorted[1][\"id\"]:\n",
    "        tools_sorted[1][\"id\"] = 2 if tools_sorted[0][\"id\"] == 1 else 1\n",
    "\n",
    "    # Combine the tools and tooltips back into the frame results\n",
    "    new_frame_results = tools_sorted + tooltips\n",
    "\n",
    "    prev_tool_positions[\"tool1\"] = tools_sorted[0][\"bbox\"] \n",
    "    prev_tool_positions[\"tool2\"] = tools_sorted[1][\"bbox\"] \n",
    "    prev_tool_positions[\"tooltip1\"] = tooltips[0][\"bbox\"] \n",
    "    prev_tool_positions[\"tooltip2\"] = tooltips[1][\"bbox\"] \n",
    "    prev_tool_positions[\"tool1conf\"] = tools_sorted[0][\"conf\"] \n",
    "    prev_tool_positions[\"tool2conf\"] = tools_sorted[1][\"conf\"] \n",
    "    prev_tool_positions[\"tooltip1conf\"] = tooltips[0][\"conf\"] \n",
    "    prev_tool_positions[\"tooltip2conf\"] = tooltips[1][\"conf\"] \n",
    "\n",
    "    return new_frame_results\n",
    "\n",
    "\n",
    "def process_input(model, input_path, output_path, images):\n",
    "    # Perform tracking on all images\n",
    "    track_start = time.time()\n",
    "    results = model.track(input_path, save=False, verbose=False, stream=True)\n",
    "    print(f\"Tracking complete in {time.time()-track_start} seconds\")\n",
    "\n",
    "    # Initialize tracking correction\n",
    "    prev_tool_positions = {\"tool1\": None, \"tool2\": None, \"tooltip1\": None, \"tooltip2\": None, \"tool1conf\": 0, \"tool2conf\": 0, \"tooltip1conf\": 0, \"tooltip2conf\": 0}\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Process each frame\n",
    "    process_time = time.time()\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for idx, frame_results in enumerate(results):\n",
    "        frame = images[idx]\n",
    "        processed_results = relabel_and_enforce_order(\n",
    "            frame_results, prev_tool_positions\n",
    "        )\n",
    "        for det in processed_results:\n",
    "            try:\n",
    "                x1, y1, x2, y2 = map(int, det[\"bbox\"])\n",
    "                cls = det[\"cls\"]\n",
    "                bounding_boxes.append([cls, x1, y1, x2, y2])\n",
    "                # make conf percent\n",
    "                label = f\"{'Tool' if det['cls'] == 0 else 'Tooltip'} #{det['id']}, {det['conf']*100:.2f}%\"\n",
    "                color = \"blue\" if cls == 0 else \"orange\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "                cv2.putText(\n",
    "                    frame, label, (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 3\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processed frame {idx+1}/{len(images)}\")\n",
    "        cv2.imwrite(os.path.join(output_path, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "\n",
    "    # Now go into the output directory and create a video\n",
    "    video_time = time.time()\n",
    "    output_video_path = os.path.join(output_path, \"output.mp4\")\n",
    "    h, w, _ = frame.shape\n",
    "    frame_files = sorted(\n",
    "        [f for f in os.listdir(output_path) if f.endswith((\".jpg\", \".png\"))]\n",
    "    )\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (w, h))\n",
    "    for frame_file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(output_path, frame_file))\n",
    "        os.remove(os.path.join(output_path, frame_file))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video saved in {time.time()-video_time} seconds in {output_video_path}\")\n",
    "\n",
    "    print(f\"Processing complete: {time.time()-process_time} seconds\")\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.75\n",
    "\n",
    "\n",
    "def calculate_black_pixel_ratio(img, bbox):\n",
    "    \"\"\"Calculate the ratio of black pixels in the bottom left quadrant to the bottom right quadrant.\"\"\"\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    tool_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Convert to grayscale and threshold to find black pixels\n",
    "    gray = cv2.cvtColor(tool_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, black_mask = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Split into quadrants\n",
    "    h, w = black_mask.shape\n",
    "    bottom_left = black_mask[h // 2 :, : w // 2]\n",
    "    bottom_right = black_mask[h // 2 :, w // 2 :]\n",
    "\n",
    "    # Calculate ratios\n",
    "    bl_ratio = np.sum(bottom_left == 255) / bottom_left.size\n",
    "    br_ratio = np.sum(bottom_right == 255) / bottom_right.size\n",
    "\n",
    "    # Return combined ratio\n",
    "    return bl_ratio + (1 - br_ratio)\n",
    "\n",
    "\n",
    "def determine_tool_order(img, tool_bboxes):\n",
    "    \"\"\"Determine which tool is left and which is right based on black pixel ratio.\"\"\"\n",
    "    left_tool_idx = 0\n",
    "    right_tool_idx = 1\n",
    "\n",
    "    # Calculate black pixel ratios for both tools\n",
    "    ratio_1 = calculate_black_pixel_ratio(img, tool_bboxes[0])\n",
    "    ratio_2 = calculate_black_pixel_ratio(img, tool_bboxes[1])\n",
    "\n",
    "    if ratio_2 > ratio_1:\n",
    "        left_tool_idx = 1\n",
    "        right_tool_idx = 0\n",
    "\n",
    "    return left_tool_idx, right_tool_idx\n",
    "\n",
    "\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    \"\"\"Calculate the Intersection over Union (IoU) of two bounding boxes.\"\"\"\n",
    "    x1 = max(bbox1[0], bbox2[0])\n",
    "    y1 = max(bbox1[1], bbox2[1])\n",
    "    x2 = min(bbox1[2], bbox2[2])\n",
    "    y2 = min(bbox1[3], bbox2[3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    bbox1_area = (bbox1[2] - bbox1[0]) * (bbox1[3] - bbox1[1])\n",
    "    bbox2_area = (bbox2[2] - bbox2[0]) * (bbox2[3] - bbox2[1])\n",
    "\n",
    "    iou = inter_area / float(bbox1_area + bbox2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def calculate_overlap(bbox1, bbox2):\n",
    "    \"\"\"Calculate the overlap area of two bounding boxes.\"\"\"\n",
    "    x1 = max(bbox1[0], bbox2[0])\n",
    "    y1 = max(bbox1[1], bbox2[1])\n",
    "    x2 = min(bbox1[2], bbox2[2])\n",
    "    y2 = min(bbox1[3], bbox2[3])\n",
    "\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    return inter_area\n",
    "\n",
    "\n",
    "# smaller value of distance from tooltip centre to tool centre multiplied by 1 - overlap ratio\n",
    "def calculate_distance(tool, tip):\n",
    "    tip_center = np.array(\n",
    "        [\n",
    "            (tip[0] + tip[2]) / 2,\n",
    "            (tip[1] + tip[3]) / 2,\n",
    "        ]\n",
    "    )\n",
    "    tool_center = np.array(\n",
    "        [\n",
    "            (tool[0] + tool[2]) / 2,\n",
    "            (tool[1] + tool[3]) / 2,\n",
    "        ]\n",
    "    )\n",
    "    distance = np.linalg.norm(tool_center - tip_center)\n",
    "    overlap = calculate_overlap(tip, tool)\n",
    "    return distance * (1 - overlap / ((tip[2] - tip[0]) * (tip[3] - tip[1])))\n",
    "\n",
    "def process_input_simpler(model, input_path, output_path, images):\n",
    "    prev_tool_positions = {\n",
    "        \"tool1\": None,\n",
    "        \"tool2\": None,\n",
    "        \"tooltip1\": None,\n",
    "        \"tooltip2\": None,\n",
    "        \"tool1conf\": 0,\n",
    "        \"tool2conf\": 0,\n",
    "        \"tooltip1conf\": 0,\n",
    "        \"tooltip2conf\": 0,\n",
    "    }\n",
    "    bounding_boxes = []\n",
    "\n",
    "    # Perform tracking on all images\n",
    "    track_start = time.time()\n",
    "    results = model.track(input_path, save=False, verbose=False, stream=True)\n",
    "    print(f\"Tracking complete in {time.time()-track_start} seconds\")\n",
    "\n",
    "    # Process each frame\n",
    "    process_time = time.time()\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for idx, frame_results in enumerate(results):\n",
    "        try:\n",
    "            frame = images[idx]\n",
    "            tools = []\n",
    "            tooltips = []\n",
    "\n",
    "            # Extract detected tools and tooltips\n",
    "            for det in frame_results.boxes:\n",
    "                cls = int(det.cls.cpu().numpy())\n",
    "                conf = det.conf.cpu().numpy()[0]\n",
    "                bbox = det.xyxy.cpu().numpy()[0]\n",
    "                if cls == 0:\n",
    "                    tools.append({\"cls\": cls, \"conf\": conf, \"bbox\": bbox})\n",
    "                elif cls == 1:\n",
    "                    tooltips.append({\"cls\": cls, \"conf\": conf, \"bbox\": bbox})\n",
    "\n",
    "            # Handle tool detections\n",
    "            if len(tools) == 2:\n",
    "                left_idx, right_idx = determine_tool_order(\n",
    "                    frame, [tools[0][\"bbox\"], tools[1][\"bbox\"]]\n",
    "                )\n",
    "                tools[left_idx][\"id\"] = 1\n",
    "                tools[right_idx][\"id\"] = 2\n",
    "                prev_tool_positions[\"tool1\"] = tools[left_idx][\"bbox\"]\n",
    "                prev_tool_positions[\"tool2\"] = tools[right_idx][\"bbox\"]\n",
    "                prev_tool_positions[\"tool1conf\"] = tools[left_idx][\"conf\"]\n",
    "                prev_tool_positions[\"tool2conf\"] = tools[right_idx][\"conf\"]\n",
    "            elif len(tools) == 1:\n",
    "                current_tool = tools[0]\n",
    "                iou_tool1 = (\n",
    "                    calculate_iou(prev_tool_positions[\"tool1\"], current_tool[\"bbox\"])\n",
    "                    if prev_tool_positions[\"tool1\"] is not None\n",
    "                    else 0\n",
    "                )\n",
    "                iou_tool2 = (\n",
    "                        calculate_iou(prev_tool_positions[\"tool2\"], current_tool[\"bbox\"])\n",
    "                        if prev_tool_positions[\"tool2\"] is not None\n",
    "                        else 0\n",
    "                )\n",
    "                if iou_tool1 > iou_tool2:\n",
    "                    current_tool[\"id\"] = 1\n",
    "                    prev_tool_positions[\"tool1\"] = current_tool[\"bbox\"]\n",
    "                    prev_tool_positions[\"tool1conf\"] = current_tool[\"conf\"]\n",
    "                    tools.append(\n",
    "                        {\n",
    "                            \"cls\": 0,\n",
    "                            \"conf\": prev_tool_positions[\"tool2conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                            \"id\": 2,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    current_tool[\"id\"] = 2\n",
    "                    prev_tool_positions[\"tool2\"] = current_tool[\"bbox\"]\n",
    "                    prev_tool_positions[\"tool2conf\"] = current_tool[\"conf\"]\n",
    "                    tools.append(\n",
    "                        {\n",
    "                            \"cls\": 0,\n",
    "                            \"conf\": prev_tool_positions[\"tool1conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                            \"id\": 1,\n",
    "                        }\n",
    "                    )\n",
    "            else:\n",
    "                # Use previous frame tools if confidence is high\n",
    "                if prev_tool_positions[\"tool1conf\"] > CONFIDENCE_THRESHOLD:\n",
    "                    tools.append(\n",
    "                        {\n",
    "                            \"cls\": 0,\n",
    "                            \"conf\": prev_tool_positions[\"tool1conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tool1\"],\n",
    "                            \"id\": 1,\n",
    "                        }\n",
    "                    )\n",
    "                if prev_tool_positions[\"tool2conf\"] > CONFIDENCE_THRESHOLD:\n",
    "                    tools.append(\n",
    "                        {\n",
    "                            \"cls\": 0,\n",
    "                            \"conf\": prev_tool_positions[\"tool2conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tool2\"],\n",
    "                            \"id\": 2,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "            # Left tooltip is always 1, right tooltip is always 2. If only one then look at overlap of the tool bbox\n",
    "            if len(tooltips) == 2:\n",
    "                # Calculate distance between tooltip and tool centers\n",
    "                dist1 = calculate_distance(tools[0][\"bbox\"], tooltips[0][\"bbox\"])\n",
    "                dist2 = calculate_distance(tools[1][\"bbox\"], tooltips[1][\"bbox\"])\n",
    "                # multiple by 1 - overlap ratio\n",
    "                dist1 *= 1 - calculate_overlap(tools[0][\"bbox\"], tooltips[0][\"bbox\"]) / (\n",
    "                    (tooltips[0][\"bbox\"][2] - tooltips[0][\"bbox\"][0])\n",
    "                    * (tooltips[0][\"bbox\"][3] - tooltips[0][\"bbox\"][1])\n",
    "                )\n",
    "                dist2 *= 1 - calculate_overlap(tools[1][\"bbox\"], tooltips[1][\"bbox\"]) / (\n",
    "                    (tooltips[1][\"bbox\"][2] - tooltips[1][\"bbox\"][0])\n",
    "                    * (tooltips[1][\"bbox\"][3] - tooltips[1][\"bbox\"][1])\n",
    "                )\n",
    "                tooltips[0][\"id\"] = 1 if dist1 < dist2 else 2\n",
    "                tooltips[1][\"id\"] = 2 if dist1 < dist2 else 1\n",
    "                prev_tool_positions[\"tooltip1\"] = tooltips[0][\"bbox\"]\n",
    "                prev_tool_positions[\"tooltip2\"] = tooltips[1][\"bbox\"]\n",
    "                prev_tool_positions[\"tooltip1conf\"] = tooltips[0][\"conf\"]\n",
    "                prev_tool_positions[\"tooltip2conf\"] = tooltips[1][\"conf\"]\n",
    "            elif len(tooltips) == 1:\n",
    "                # Check overlap using calculate_overlap\n",
    "                current_tooltip = tooltips[0]\n",
    "                iou_tooltip1 = (\n",
    "                    calculate_overlap(prev_tool_positions[\"tool1\"], current_tooltip[\"bbox\"])\n",
    "                    if prev_tool_positions[\"tool1\"] is not None\n",
    "                    else 0\n",
    "                )\n",
    "                iou_tooltip2 = (\n",
    "                    calculate_overlap(prev_tool_positions[\"tool2\"], current_tooltip[\"bbox\"])\n",
    "                    if prev_tool_positions[\"tool2\"] is not None\n",
    "                    else 0\n",
    "                )\n",
    "                if iou_tooltip1 > iou_tooltip2:\n",
    "                    current_tooltip[\"id\"] = 1\n",
    "                    prev_tool_positions[\"tooltip1\"] = current_tooltip[\"bbox\"]\n",
    "                    prev_tool_positions[\"tooltip1conf\"] = current_tooltip[\"conf\"]\n",
    "                    tooltips.append(\n",
    "                        {\n",
    "                            \"cls\": 1,\n",
    "                            \"conf\": prev_tool_positions[\"tooltip2conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                            \"id\": 2,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    current_tooltip[\"id\"] = 2\n",
    "                    prev_tool_positions[\"tooltip2\"] = current_tooltip[\"bbox\"]\n",
    "                    prev_tool_positions[\"tooltip2conf\"] = current_tooltip[\"conf\"]\n",
    "                    tooltips.append(\n",
    "                        {\n",
    "                            \"cls\": 1,\n",
    "                            \"conf\": prev_tool_positions[\"tooltip1conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                            \"id\": 1,\n",
    "                        }\n",
    "                    )\n",
    "            else:\n",
    "                # Use previous frame tooltips if confidence is high\n",
    "                if prev_tool_positions[\"tooltip1conf\"] > CONFIDENCE_THRESHOLD:\n",
    "                    tooltips.append(\n",
    "                        {\n",
    "                            \"cls\": 1,\n",
    "                            \"conf\": prev_tool_positions[\"tooltip1conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tooltip1\"],\n",
    "                            \"id\": 1,\n",
    "                        }\n",
    "                    )\n",
    "                if prev_tool_positions[\"tooltip2conf\"] > CONFIDENCE_THRESHOLD:\n",
    "                    tooltips.append(\n",
    "                        {\n",
    "                            \"cls\": 1,\n",
    "                            \"conf\": prev_tool_positions[\"tooltip2conf\"],\n",
    "                            \"bbox\": prev_tool_positions[\"tooltip2\"],\n",
    "                            \"id\": 2,\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    \n",
    "\n",
    "            # If only tooltips are detected and no tools, use the leftmost and rightmost positions\n",
    "            if len(tools) == 0 and len(tooltips) > 0:\n",
    "                sorted_tooltips = sorted(\n",
    "                    tooltips, key=lambda x: x[\"bbox\"][2]\n",
    "                )  # Sort by bottom-right x-coordinate\n",
    "                sorted_tooltips[0][\"id\"] = 1  # Leftmost\n",
    "                if len(sorted_tooltips) > 1:\n",
    "                    sorted_tooltips[1][\"id\"] = 2  # Rightmost\n",
    "\n",
    "            # Annotate and save frame\n",
    "            for det in tools + tooltips:\n",
    "                if det[\"conf\"] > CONFIDENCE_THRESHOLD:\n",
    "                    x1, y1, x2, y2 = map(int, det[\"bbox\"])\n",
    "                    cls = det[\"cls\"]\n",
    "                    bounding_boxes.append([cls, x1, y1, x2, y2])\n",
    "                    label = f\"{'Tool' if cls == 0 else 'Tooltip'} #{det['id']}, {det['conf']*100:.2f}%\"\n",
    "                    color = (255, 0, 0) if det[\"id\"] == 1 else (0, 0, 255)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "                    cv2.putText(\n",
    "                        frame, label, (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 3\n",
    "                    )\n",
    "\n",
    "            # Update previous positions\n",
    "            for det in tools:\n",
    "                if det[\"id\"] == 1:\n",
    "                    prev_tool_positions[\"tool1\"] = det[\"bbox\"]\n",
    "                    prev_tool_positions[\"tool1conf\"] = det[\"conf\"]\n",
    "                elif det[\"id\"] == 2:\n",
    "                    prev_tool_positions[\"tool2\"] = det[\"bbox\"]\n",
    "                    prev_tool_positions[\"tool2conf\"] = det[\"conf\"]\n",
    "\n",
    "            for det in tooltips:\n",
    "                if det[\"id\"] == 1:\n",
    "                    prev_tool_positions[\"tooltip1\"] = det[\"bbox\"]\n",
    "                    prev_tool_positions[\"tooltip1conf\"] = det[\"conf\"]\n",
    "                elif det[\"id\"] == 2:\n",
    "                    prev_tool_positions[\"tooltip2\"] = det[\"bbox\"]\n",
    "                    prev_tool_positions[\"tooltip2conf\"] = det[\"conf\"]\n",
    "\n",
    "            # Save the frame\n",
    "            cv2.imwrite(os.path.join(output_path, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"Processed frame {idx+1}/{len(images)}\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Now go into the output directory and create a video\n",
    "    video_time = time.time()\n",
    "    output_video_path = os.path.join(output_path, \"new_tracking.mp4\")\n",
    "    h, w, _ = frame.shape\n",
    "    frame_files = sorted(\n",
    "        [f for f in os.listdir(output_path) if f.endswith((\".jpg\", \".png\"))]\n",
    "    )\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (w, h))\n",
    "    for frame_file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(output_path, frame_file))\n",
    "        os.remove(os.path.join(output_path, frame_file))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video saved in {time.time()-video_time} seconds in {output_video_path}\")\n",
    "    print(f\"Processing complete: {time.time()-process_time} seconds\")\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the issues with tool and tooltip tracking, we'll adjust the logic for handling cases where only one tool or tooltip is detected, ensuring proper ID assignment and consistent frame-by-frame tracking. Heres the updated version of `process_input_simpler`:\n",
    "### Summary of Key Updates:\n",
    "\n",
    "1. **Tool Detection Logic**: \n",
    "   - If two tools are detected, they are assigned IDs based on their position and black pixel ratio.\n",
    "   - If only one tool is detected, its ID is determined by comparing the IoU with the previous tools.\n",
    "   - If no tools are detected, we carry over tools from the previous frame only if their confidence was above the threshold.\n",
    "\n",
    "2. **Tooltip Detection Logic**: \n",
    "   - Tooltips are matched to the closest tool, with the same ID as the tool they are closest to.\n",
    "   - If no tools are detected, but tooltips are, they are assigned IDs based on their horizontal position.\n",
    "\n",
    "3. **Consistency Check**: \n",
    "   - We ensure no duplicate IDs by reordering and correcting IDs if needed.\n",
    "\n",
    "4. **Updating Previous Positions**: \n",
    "   - The previous positions and confidence levels are updated at the end of processing each frame, ensuring that the tracking remains consistent across frames.\n",
    "\n",
    "This should now handle the edge cases you mentioned and improve the robustness of tracking tools and tooltips across frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "CONFIDENCE_THRESHOLD = 0.75\n",
    "\n",
    "\n",
    "def get_bottom_left_coord(bbox):\n",
    "    \"\"\"Return the bottom-left coordinate of a bounding box.\"\"\"\n",
    "    x1, y2 = bbox[0], bbox[3]\n",
    "    return (x1, y2)\n",
    "\n",
    "\n",
    "def get_center_coord(bbox):\n",
    "    \"\"\"Return the centre coordinate of a bounding box.\"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cx = (x1 + x2) / 2\n",
    "    cy = (y1 + y2) / 2\n",
    "    return (cx, cy)\n",
    "\n",
    "\n",
    "def assign_left_right(detections, prev_left_bbox=None, prev_right_bbox=None):\n",
    "    \"\"\"Assign left and right based on the bottom-left coordinates or previous frames.\"\"\"\n",
    "    if len(detections) == 2:\n",
    "        bl1 = get_bottom_left_coord(detections[0][\"bbox\"])\n",
    "        bl2 = get_bottom_left_coord(detections[1][\"bbox\"])\n",
    "        if bl1[0] < bl2[0]:\n",
    "            detections[0][\"id\"] = 1  # Left\n",
    "            detections[1][\"id\"] = 2  # Right\n",
    "        else:\n",
    "            detections[0][\"id\"] = 2  # Right\n",
    "            detections[1][\"id\"] = 1  # Left\n",
    "    elif len(detections) == 1:\n",
    "        if prev_left_bbox is None and prev_right_bbox is None:\n",
    "            detections[0][\"id\"] = 1  # Assume it's left if no previous data\n",
    "        else:\n",
    "            current_center = get_center_coord(detections[0][\"bbox\"])\n",
    "            dist_to_left = (\n",
    "                np.linalg.norm(\n",
    "                    np.array(current_center)\n",
    "                    - np.array(get_center_coord(prev_left_bbox))\n",
    "                )\n",
    "                if prev_left_bbox is not None\n",
    "                else float(\"inf\")\n",
    "            )\n",
    "            dist_to_right = (\n",
    "                np.linalg.norm(\n",
    "                    np.array(current_center)\n",
    "                    - np.array(get_center_coord(prev_right_bbox))\n",
    "                )\n",
    "                if prev_right_bbox is not None\n",
    "                else float(\"inf\")\n",
    "            )\n",
    "            if dist_to_left < dist_to_right:\n",
    "                detections[0][\"id\"] = 1  # Closer to previous left\n",
    "            else:\n",
    "                detections[0][\"id\"] = 2  # Closer to previous right\n",
    "\n",
    "\n",
    "def process_input_simplest(model, input_path, output_path, images):\n",
    "    bounding_boxes = []\n",
    "    prev_tool_left = prev_tool_right = prev_tooltip_left = prev_tooltip_right = None\n",
    "\n",
    "    # Perform tracking on all images\n",
    "    track_start = time.time()\n",
    "    results = model.track(input_path, save=False, verbose=False, stream=True)\n",
    "    print(f\"Tracking complete in {time.time()-track_start} seconds\")\n",
    "\n",
    "    # Process each frame\n",
    "    process_time = time.time()\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    for idx, frame_results in enumerate(results):\n",
    "        frame = images[idx]\n",
    "        tools = []\n",
    "        tooltips = []\n",
    "\n",
    "        # Extract detected tools and tooltips\n",
    "        for det in frame_results.boxes:\n",
    "            cls = int(det.cls.cpu().numpy())\n",
    "            conf = det.conf.cpu().numpy()[0]\n",
    "            bbox = det.xyxy.cpu().numpy()[0]\n",
    "            if cls == 0 and conf > CONFIDENCE_THRESHOLD:\n",
    "                tools.append({\"cls\": cls, \"conf\": conf, \"bbox\": bbox})\n",
    "            elif cls == 1 and conf > CONFIDENCE_THRESHOLD:\n",
    "                tooltips.append({\"cls\": cls, \"conf\": conf, \"bbox\": bbox})\n",
    "\n",
    "        # Assign left and right to tools and tooltips\n",
    "        assign_left_right(tools, prev_tool_left, prev_tool_right)\n",
    "        assign_left_right(tooltips, prev_tooltip_left, prev_tooltip_right)\n",
    "\n",
    "        # Store the previous bounding boxes for the next frame\n",
    "        for tool in tools:\n",
    "            try:\n",
    "                if tool[\"id\"] == 1:\n",
    "                    prev_tool_left = tool[\"bbox\"]\n",
    "                elif tool[\"id\"] == 2:\n",
    "                    prev_tool_right = tool[\"bbox\"]\n",
    "            except:\n",
    "                pass\n",
    "        for tip in tooltips:\n",
    "            try:\n",
    "                if tip[\"id\"] == 1:\n",
    "                    prev_tooltip_left = tip[\"bbox\"]\n",
    "                elif tip[\"id\"] == 2:\n",
    "                    prev_tooltip_right = tip[\"bbox\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Annotate and save frame\n",
    "        for det in tools + tooltips:\n",
    "            try:\n",
    "                x1, y1, x2, y2 = map(int, det[\"bbox\"])\n",
    "                cls = det[\"cls\"]\n",
    "                bounding_boxes.append([cls, x1, y1, x2, y2])\n",
    "                label = f\"{'Tool' if cls == 0 else 'Tooltip'} #{det['id']}, {det['conf']*100:.2f}%\"\n",
    "                color = (255, 0, 0) if det[\"id\"] == 1 else (0, 0, 255)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
    "                cv2.putText(\n",
    "                    frame, label, (x1, y1 - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 3\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Save the frame\n",
    "        cv2.imwrite(os.path.join(output_path, f\"frame_{idx:04d}.jpg\"), frame)\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Processed frame {idx+1}/{len(images)}\")\n",
    "\n",
    "    # Now go into the output directory and create a video\n",
    "    video_time = time.time()\n",
    "    output_video_path = os.path.join(output_path, \"easy_tracking.mp4\")\n",
    "    h, w, _ = frame.shape\n",
    "    frame_files = sorted(\n",
    "        [f for f in os.listdir(output_path) if f.endswith((\".jpg\", \".png\"))]\n",
    "    )\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, 20.0, (w, h))\n",
    "    for frame_file in frame_files:\n",
    "        frame = cv2.imread(os.path.join(output_path, frame_file))\n",
    "        os.remove(os.path.join(output_path, frame_file))\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "    print(f\"Video saved in {time.time()-video_time} seconds in {output_video_path}\")\n",
    "    print(f\"Processing complete: {time.time()-process_time} seconds\")\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLOv10\n",
    "import time\n",
    "# \"n\", \"s\", \"m\", \"b\", \"l\",\n",
    "for n in [\"x\"]: \n",
    "    start_time = time.time()\n",
    "    model = YOLOv10(f\"chkpts/6DOF/v10{n}/yolov10{n}-detect-6dof/weights/best.pt\").to(\n",
    "        \"cuda\"\n",
    "    )\n",
    "    print(f\"Loaded model in {time.time()-start_time} seconds\")\n",
    "    # process_input(\n",
    "    #     model,\n",
    "    #     \"data/6DOF/images/val\",\n",
    "    #     f\"chkpts/6DOF/v10{n}/tracking\",\n",
    "    #     load_images(\"data/6DOF/images/val\"),\n",
    "    # )\n",
    "    # process_input_simpler(\n",
    "    #     model,\n",
    "    #     \"data/6DOF/images/val\",\n",
    "    #     f\"chkpts/6DOF/v10{n}/focused_tracking\",\n",
    "    #     load_images(\"data/6DOF/images/val\"),\n",
    "    # )\n",
    "    process_input_simplest(\n",
    "        model,\n",
    "        \"data/6DOF/images/val\",\n",
    "        f\"chkpts/6DOF/v10{n}/easy_tracking\",\n",
    "        load_images(\"data/6DOF/images/val\"),\n",
    "    )\n",
    "    print(\"Done with\", n, f\"in {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "for n in [\"n\", \"s\", \"m\", \"l\", \"x\"]:\n",
    "    start_time = time.time()\n",
    "    model = YOLO(f\"chkpts/6DOF/v8{n}/yolov8{n}-detect-6dof/weights/best.pt\").to(\n",
    "        \"cuda\"\n",
    "    )\n",
    "    print(f\"Loaded model in {time.time()-start_time} seconds\")\n",
    "    # process_input(\n",
    "    #     model,\n",
    "    #     \"data/6DOF/images/val\",\n",
    "    #     f\"chkpts/6DOF/v8{n}/tracking\",\n",
    "    #     load_images(\"data/6DOF/images/val\"),\n",
    "    # )\n",
    "    # process_input_simpler(\n",
    "    #     model,\n",
    "    #     \"data/6DOF/images/val\",\n",
    "    #     f\"chkpts/6DOF/v8{n}/focused_tracking\",\n",
    "    #     load_images(\"data/6DOF/images/val\"),\n",
    "    # )\n",
    "    process_input_simplest(\n",
    "        model,\n",
    "        \"data/6DOF/images/val\",\n",
    "        f\"chkpts/6DOF/v8{n}/easy_tracking\",\n",
    "        load_images(\"data/6DOF/images/val\"),\n",
    "    )\n",
    "    print(\"Done with\", n, f\"in {time.time()-start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def draw_bounding_boxes_with_opacity(\n",
    "    image_path, bounding_boxes, output_path, alpha_decay=0.1\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on an image with decreasing opacity for older boxes.\n",
    "\n",
    "    :param image_path: Path to the final image.\n",
    "    :param bounding_boxes: List of bounding boxes in the format [class_id, x1, y1, x2, y2].\n",
    "    :param output_path: Path to save the output image.\n",
    "    :param alpha_decay: Amount by which opacity decreases for older boxes.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    overlay = image.copy()\n",
    "\n",
    "    # Sort bounding boxes by class_id to apply opacity correctly\n",
    "    bounding_boxes.reverse()\n",
    "\n",
    "    for i, box in enumerate(bounding_boxes):\n",
    "        class_id, x1, y1, x2, y2 = box\n",
    "        if class_id == 0:\n",
    "            continue\n",
    "        alpha = 1 - i * alpha_decay\n",
    "        alpha = max(alpha, 0.01)  # Ensure a minimum opacity level\n",
    "\n",
    "        # set green\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # Draw the bounding box with reduced opacity with no fill (just the lines)\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), color, 2)\n",
    "        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Image saved with bounding boxes at {output_path}\")\n",
    "\n",
    "# Paths\n",
    "image_path = \"data/6DOF/images/test/test5_319.png\"\n",
    "output_path = \"final_image_with_boxes.png\"\n",
    "\n",
    "# Draw the bounding boxes\n",
    "# draw_bounding_boxes_with_opacity(image_path, bounding_boxes, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLOv10\n",
    "\n",
    "\n",
    "def process_images(input_dir, output_dir, model):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Process each image in the input directory\n",
    "    for filename in sorted(os.listdir(input_dir)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(input_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            # if label file already exists, skip\n",
    "            if os.path.exists(os.path.join(output_dir, filename.replace(\".png\", \".txt\"))):\n",
    "                continue\n",
    "            # Perform inference using the YOLO model\n",
    "            results = model(img, verbose=False)\n",
    "\n",
    "            # Get the top 2 confidence values for each class (tool = 0, tooltip = 1)\n",
    "            detections = results[0].boxes\n",
    "            # if no detections then write empty file and continue\n",
    "            if len(detections) == 0:\n",
    "                with open(os.path.join(output_dir, filename.replace(\".png\", \".txt\")), \"w\") as f:\n",
    "                    f.write(\"\")\n",
    "                continue\n",
    "            tools = [det for det in detections if det.cls == 0]\n",
    "            tooltips = [det for det in detections if det.cls == 1]\n",
    "\n",
    "            tools_sorted = sorted(tools, key=lambda x: x.conf, reverse=True)[:2]\n",
    "            tooltips_sorted = sorted(tooltips, key=lambda x: x.conf, reverse=True)[:2]\n",
    "\n",
    "            # Combine and format detections for YOLO format\n",
    "            all_detections = tools_sorted + tooltips_sorted\n",
    "            yolo_format_data = []\n",
    "            for det in all_detections:\n",
    "                try:\n",
    "                    bbox = det.xywh[0].cpu().numpy()\n",
    "                    cls = int(det.cls.cpu().numpy())\n",
    "                    x_center, y_center, width, height = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "                    # Normalize coordinates by image dimensions\n",
    "                    x_center /= img.shape[1]\n",
    "                    y_center /= img.shape[0]\n",
    "                    width /= img.shape[1]\n",
    "                    height /= img.shape[0]\n",
    "                    yolo_format_data.append(\n",
    "                        f\"{cls} {x_center} {y_center} {width} {height}/n\"\n",
    "                    )\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # Save the results in the corresponding txt file\n",
    "            output_txt_path = os.path.join(\n",
    "                output_dir, filename.replace(\".png\", \".txt\").replace(\".jpg\", \".txt\")\n",
    "            )\n",
    "            with open(output_txt_path, \"w\") as f:\n",
    "                f.writelines(yolo_format_data)\n",
    "\n",
    "            print(f\"Processed {filename} and saved results to {output_txt_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your YOLO model\n",
    "    model = YOLOv10(\"chkpts/6DOF/v10x/yolov10x-detect-6dof/weights/best.pt\").to(device)\n",
    "\n",
    "    for i in range(1, 25):\n",
    "        if i == 5:\n",
    "            continue\n",
    "        input_dir = f\"H:/Data/6DOF/Test {i} png\"\n",
    "        output_dir = f\"H:/Data/6DOF/Test {i} txt\"\n",
    "        if os.path.exists(input_dir):\n",
    "            process_images(input_dir, output_dir, model)\n",
    "        else:\n",
    "            print(f\"Directory {input_dir} does not exist. Skipping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from ultralytics import YOLOv10\n",
    "\n",
    "\n",
    "def draw_arrow(image, start_point, end_point, color, thickness=2):\n",
    "    \"\"\"Draw an arrow on the image from start_point to end_point.\"\"\"\n",
    "    cv2.arrowedLine(image, start_point, end_point, color, thickness, tipLength=0.3)\n",
    "\n",
    "\n",
    "def quaternion_to_axes(q):\n",
    "    \"\"\"Convert quaternion to x, y, z axes vectors.\"\"\"\n",
    "    rotation = R.from_quat(q)\n",
    "    x_axis = rotation.apply([1, 0, 0])\n",
    "    y_axis = rotation.apply([0, 1, 0])\n",
    "    z_axis = rotation.apply([0, 0, 1])\n",
    "    return x_axis, y_axis, z_axis\n",
    "\n",
    "\n",
    "def process_single_image(image_path, label_file, model):\n",
    "    \"\"\"Process a single image and draw arrows for the tooltip positions.\"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Perform YOLO detection\n",
    "    results = model(image, save=False, verbose=False)\n",
    "    detections = results[0].boxes\n",
    "\n",
    "    # Get the top 2 confidence detections for tools and tooltips\n",
    "    tools = [det for det in detections if det.cls == 0]\n",
    "    tooltips = [det for det in detections if det.cls == 1]\n",
    "\n",
    "    tools_sorted = sorted(tools, key=lambda x: x.conf, reverse=True)[:2]\n",
    "    tooltips_sorted = sorted(tooltips, key=lambda x: x.conf, reverse=True)[:2]\n",
    "\n",
    "    # Load pose data from label file\n",
    "    with open(label_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    fenestrated_pose = list(\n",
    "        map(float, lines[2].split()[1:])\n",
    "    )  # Fenestrated pose (x, y, z, qx, qy, qz, qw)\n",
    "    curved_pose = list(\n",
    "        map(float, lines[3].split()[1:])\n",
    "    )  # Curved pose (x, y, z, qx, qy, qz, qw)\n",
    "\n",
    "    # Define colors for the arrows (Fenestrated: Blue, Curved: Orange)\n",
    "    arrow_colors = {\n",
    "        1: (255, 0, 0),  # Blue for Fenestrated\n",
    "        2: (0, 165, 255),  # Orange for Curved\n",
    "    }\n",
    "\n",
    "    # Map the tool ID to the respective pose\n",
    "    tool_pose_map = {1: fenestrated_pose, 2: curved_pose}\n",
    "\n",
    "    # Draw arrows based on tooltip positions and quaternion data\n",
    "    for tool_id, tooltip in enumerate(tooltips_sorted):\n",
    "        bbox = tooltip.xyxy[0].cpu().numpy().astype(int)\n",
    "        center_x = (bbox[0] + bbox[2]) // 2\n",
    "        center_y = (bbox[1] + bbox[3]) // 2\n",
    "\n",
    "        pose = tool_pose_map[tool_id+1]\n",
    "        q = pose[3:7]  # Extract quaternion (qx, qy, qz, qw)\n",
    "\n",
    "        # Get orientation vectors (axes) from quaternion\n",
    "        x_axis, y_axis, z_axis = quaternion_to_axes(q)\n",
    "\n",
    "        # Draw arrows for x, y, z axes\n",
    "        arrow_length = 50  # Length of arrows\n",
    "        end_point_x = (\n",
    "            int(center_x + x_axis[0] * arrow_length),\n",
    "            int(center_y + x_axis[1] * arrow_length),\n",
    "        )\n",
    "        end_point_y = (\n",
    "            int(center_x + y_axis[0] * arrow_length),\n",
    "            int(center_y + y_axis[1] * arrow_length),\n",
    "        )\n",
    "        end_point_z = (\n",
    "            int(center_x + z_axis[0] * arrow_length),\n",
    "            int(center_y + z_axis[1] * arrow_length),\n",
    "        )\n",
    "\n",
    "        draw_arrow(\n",
    "            image, (center_x, center_y), end_point_x, arrow_colors[tool_id+1], thickness=2\n",
    "        )\n",
    "        draw_arrow(\n",
    "            image, (center_x, center_y), end_point_y, (0, 255, 0), thickness=2\n",
    "        )  # Green for y-axis\n",
    "        draw_arrow(\n",
    "            image, (center_x, center_y), end_point_z, (255, 0, 255), thickness=2\n",
    "        )  # Magenta for z-axis\n",
    "\n",
    "    # Save the image with arrows drawn\n",
    "    output_image_path = image_path.replace(\".png\", \"_with_arrows.png\")\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "    print(f\"Processed image saved as {output_image_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your YOLO model\n",
    "    model = YOLOv10(\"chkpts/6DOF/v10x/yolov10x-detect-6dof/weights/best.pt\").to(\"cuda\")\n",
    "\n",
    "    # Specify the input image and label file\n",
    "    image_path = \"H:/Data/6DOF/Test 2 png/test2_0000.png\"\n",
    "    label_file = \"H:/Data/6DOF/Test 2/0.txt\"\n",
    "\n",
    "    # Process the image\n",
    "    process_single_image(image_path, label_file, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
